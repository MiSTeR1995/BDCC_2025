{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "451aa704-a91e-4ca0-bb4e-1ab57b4a6c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "План (первые 20 строк):\n",
      "   video_id                                                                     src            dst_name\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_001.mp4 -7UpRmNVJzQ_001.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_002.mp4 -7UpRmNVJzQ_002.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_003.mp4 -7UpRmNVJzQ_003.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_004.mp4 -7UpRmNVJzQ_004.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_005.mp4 -7UpRmNVJzQ_005.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_006.mp4 -7UpRmNVJzQ_006.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_007.mp4 -7UpRmNVJzQ_007.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_008.mp4 -7UpRmNVJzQ_008.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_009.mp4 -7UpRmNVJzQ_009.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_010.mp4 -7UpRmNVJzQ_010.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_011.mp4 -7UpRmNVJzQ_011.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_012.mp4 -7UpRmNVJzQ_012.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_013.mp4 -7UpRmNVJzQ_013.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_014.mp4 -7UpRmNVJzQ_014.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_015.mp4 -7UpRmNVJzQ_015.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_016.mp4 -7UpRmNVJzQ_016.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_017.mp4 -7UpRmNVJzQ_017.mp4\n",
      "0FbNUlG6xpg E:\\WSM\\depression\\train_labels\\0FbNUlG6xpg\\segments\\0FbNUlG6xpg_001.mp4 0FbNUlG6xpg_001.mp4\n",
      "0FbNUlG6xpg E:\\WSM\\depression\\train_labels\\0FbNUlG6xpg\\segments\\0FbNUlG6xpg_002.mp4 0FbNUlG6xpg_002.mp4\n",
      "0FbNUlG6xpg E:\\WSM\\depression\\train_labels\\0FbNUlG6xpg\\segments\\0FbNUlG6xpg_003.mp4 0FbNUlG6xpg_003.mp4\n",
      "\n",
      "Готово. Маппинг сохранён в E:\\WSM\\depression\\segments_map.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\depression\")\n",
    "LIST_SETS = [\"dev_labels\", \"test_labels\", \"train_labels\"]\n",
    "VIDEO_EXTS = {\".mp4\", \".avi\", \".mov\", \".mkv\", \".wmv\", \".mpg\", \".mpeg\", \".m4v\", \".flv\", \".webm\", \".wav\"}\n",
    "DRY_RUN = True  # False = реально переименовать\n",
    "\n",
    "def natural_key(s: str):\n",
    "    return [int(t) if t.isdigit() else t.lower() for t in re.findall(r'\\d+|\\D+', s)]\n",
    "\n",
    "def plan_segment_renames(vid_dir: Path):\n",
    "    seg_dir = vid_dir / \"segments\"\n",
    "    if not seg_dir.is_dir():\n",
    "        return []\n",
    "\n",
    "    files = [p for p in seg_dir.iterdir() if p.is_file() and p.suffix.lower() in VIDEO_EXTS]\n",
    "    if not files:\n",
    "        return []\n",
    "\n",
    "    files_sorted = sorted(files, key=lambda p: natural_key(p.name))\n",
    "    pad = max(3, len(str(len(files_sorted))))\n",
    "\n",
    "    video_id = vid_dir.name\n",
    "    plan = []\n",
    "    for i, src in enumerate(files_sorted, 1):\n",
    "        dst_name = f\"{video_id}_{str(i).zfill(pad)}{src.suffix.lower()}\"\n",
    "        dst = src.with_name(dst_name)\n",
    "        plan.append({\n",
    "            \"video_id\": video_id,\n",
    "            \"src\": str(src),\n",
    "            \"dst\": str(dst),\n",
    "            \"dst_name\": dst_name\n",
    "        })\n",
    "    return plan\n",
    "\n",
    "def execute_plan(rows):\n",
    "    for r in rows:\n",
    "        src = Path(r[\"src\"])\n",
    "        dst = Path(r[\"dst\"])\n",
    "        if src.exists() and src.name != dst.name:\n",
    "            src.rename(dst)\n",
    "\n",
    "def main():\n",
    "    whole_plan = []\n",
    "    for split in LIST_SETS:\n",
    "        split_dir = BASE / split\n",
    "        if not split_dir.is_dir():\n",
    "            continue\n",
    "        for vid_dir in split_dir.iterdir():\n",
    "            if vid_dir.is_dir():\n",
    "                whole_plan.extend(plan_segment_renames(vid_dir))\n",
    "\n",
    "    if not whole_plan:\n",
    "        print(\"Сегментов нет, нечего писать.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(whole_plan)\n",
    "    view = df[[\"video_id\", \"src\", \"dst_name\"]].sort_values([\"video_id\", \"dst_name\"])\n",
    "    print(\"\\nПлан (первые 20 строк):\")\n",
    "    print(view.head(20).to_string(index=False))\n",
    "\n",
    "    if not DRY_RUN:\n",
    "        execute_plan(whole_plan)\n",
    "\n",
    "    # CSV только с маппингом: video_id -> segment_file\n",
    "    mapping = df[[\"video_id\", \"dst_name\"]].rename(columns={\"dst_name\": \"segment_file\"})\n",
    "    mapping.to_csv(BASE / \"segments_map.csv\", index=False)\n",
    "    print(f\"\\nГотово. Маппинг сохранён в {BASE/'segments_map.csv'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be8b7fc-d52a-4f01-a1b1-c71b76f18f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf40838c-e8ce-4737-a135-505b1ec4ec49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Обработка dev_labels ===\n",
      "Сохранил E:\\WSM\\depression\\dev_labels_with_segments.csv (строк: 663)\n",
      "\n",
      "=== Обработка test_labels ===\n",
      "Сохранил E:\\WSM\\depression\\test_labels_with_segments.csv (строк: 881)\n",
      "\n",
      "=== Обработка train_labels ===\n",
      "Сохранил E:\\WSM\\depression\\train_labels_with_segments.csv (строк: 3832)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\depression\")\n",
    "SETS = [\"dev_labels\", \"test_labels\", \"train_labels\"]\n",
    "\n",
    "for split in SETS:\n",
    "    csv_path = BASE / f\"{split}.csv\"\n",
    "    dir_path = BASE / split\n",
    "\n",
    "    print(f\"\\n=== Обработка {split} ===\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    new_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        video_id = str(row[\"video_id\"])\n",
    "        seg_dir = dir_path / video_id / \"segments\"\n",
    "\n",
    "        if seg_dir.is_dir():\n",
    "            files = sorted(os.listdir(seg_dir))\n",
    "            for f in files:\n",
    "                new_row = row.copy()\n",
    "                new_row[\"segment_file\"] = f\n",
    "                new_rows.append(new_row)\n",
    "        else:\n",
    "            # нет сегментов — добавляем как есть (без segment_file)\n",
    "            new_row = row.copy()\n",
    "            new_row[\"segment_file\"] = None\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "    df_new = pd.DataFrame(new_rows)\n",
    "\n",
    "    # сохраняем как отдельный файл (чтобы не угробить оригинал)\n",
    "    out_path = BASE / f\"{split}_with_segments.csv\"\n",
    "    df_new.to_csv(out_path, index=False)\n",
    "    print(f\"Сохранил {out_path} (строк: {len(df_new)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a46ef8e0-5419-40ce-8fe6-49246ef87dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "План (первые 20 строк):\n",
      "   video_id                                                                                                                                    src            dst_name\n",
      "3MKVlrQoHD4       E:\\WSM\\parkinson\\dev_labels\\3MKVlrQoHD4\\segments\\Can Microdosing Psilocybin Magic Mushrooms help with Parkinsons disease_000.mp4 3MKVlrQoHD4_001.mp4\n",
      "3MKVlrQoHD4       E:\\WSM\\parkinson\\dev_labels\\3MKVlrQoHD4\\segments\\Can Microdosing Psilocybin Magic Mushrooms help with Parkinsons disease_001.mp4 3MKVlrQoHD4_002.mp4\n",
      "3MKVlrQoHD4       E:\\WSM\\parkinson\\dev_labels\\3MKVlrQoHD4\\segments\\Can Microdosing Psilocybin Magic Mushrooms help with Parkinsons disease_002.mp4 3MKVlrQoHD4_003.mp4\n",
      "3MKVlrQoHD4       E:\\WSM\\parkinson\\dev_labels\\3MKVlrQoHD4\\segments\\Can Microdosing Psilocybin Magic Mushrooms help with Parkinsons disease_003.mp4 3MKVlrQoHD4_004.mp4\n",
      "3MKVlrQoHD4       E:\\WSM\\parkinson\\dev_labels\\3MKVlrQoHD4\\segments\\Can Microdosing Psilocybin Magic Mushrooms help with Parkinsons disease_004.mp4 3MKVlrQoHD4_005.mp4\n",
      "3bHJDSws_jQ E:\\WSM\\parkinson\\dev_labels\\3bHJDSws_jQ\\segments\\Update on my 24 Hour Water Fast Living with Parkinsons Disease & Lyme Disease_000.mp4 3bHJDSws_jQ_001.mp4\n",
      "3bHJDSws_jQ E:\\WSM\\parkinson\\dev_labels\\3bHJDSws_jQ\\segments\\Update on my 24 Hour Water Fast Living with Parkinsons Disease & Lyme Disease_001.mp4 3bHJDSws_jQ_002.mp4\n",
      "3bHJDSws_jQ E:\\WSM\\parkinson\\dev_labels\\3bHJDSws_jQ\\segments\\Update on my 24 Hour Water Fast Living with Parkinsons Disease & Lyme Disease_002.mp4 3bHJDSws_jQ_003.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_000.mp4 4-d_F3MczUE_001.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_001.mp4 4-d_F3MczUE_002.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_002.mp4 4-d_F3MczUE_003.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_003.mp4 4-d_F3MczUE_004.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_004.mp4 4-d_F3MczUE_005.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_005.mp4 4-d_F3MczUE_006.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_006.mp4 4-d_F3MczUE_007.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_007.mp4 4-d_F3MczUE_008.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_008.mp4 4-d_F3MczUE_009.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_009.mp4 4-d_F3MczUE_010.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_010.mp4 4-d_F3MczUE_011.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_011.mp4 4-d_F3MczUE_012.mp4\n",
      "\n",
      "Готово. Маппинг сохранён в E:\\WSM\\parkinson\\segments_map.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\parkinson\")\n",
    "LIST_SETS = [\"dev_labels\"]\n",
    "VIDEO_EXTS = {\".mp4\", \".avi\", \".mov\", \".mkv\", \".wmv\", \".mpg\", \".mpeg\", \".m4v\", \".flv\", \".webm\", \".wav\"}\n",
    "DRY_RUN = False  # False = реально переименовать\n",
    "\n",
    "def natural_key(s: str):\n",
    "    return [int(t) if t.isdigit() else t.lower() for t in re.findall(r'\\d+|\\D+', s)]\n",
    "\n",
    "def plan_segment_renames(vid_dir: Path):\n",
    "    seg_dir = vid_dir / \"segments\"\n",
    "    if not seg_dir.is_dir():\n",
    "        return []\n",
    "\n",
    "    files = [p for p in seg_dir.iterdir() if p.is_file() and p.suffix.lower() in VIDEO_EXTS]\n",
    "    if not files:\n",
    "        return []\n",
    "\n",
    "    files_sorted = sorted(files, key=lambda p: natural_key(p.name))\n",
    "    pad = max(3, len(str(len(files_sorted))))\n",
    "\n",
    "    video_id = vid_dir.name\n",
    "    plan = []\n",
    "    for i, src in enumerate(files_sorted, 1):\n",
    "        dst_name = f\"{video_id}_{str(i).zfill(pad)}{src.suffix.lower()}\"\n",
    "        dst = src.with_name(dst_name)\n",
    "        plan.append({\n",
    "            \"video_id\": video_id,\n",
    "            \"src\": str(src),\n",
    "            \"dst\": str(dst),\n",
    "            \"dst_name\": dst_name\n",
    "        })\n",
    "    return plan\n",
    "\n",
    "def execute_plan(rows):\n",
    "    for r in rows:\n",
    "        src = Path(r[\"src\"])\n",
    "        dst = Path(r[\"dst\"])\n",
    "        if src.exists() and src.name != dst.name:\n",
    "            src.rename(dst)\n",
    "\n",
    "def main():\n",
    "    whole_plan = []\n",
    "    for split in LIST_SETS:\n",
    "        split_dir = BASE / split\n",
    "        if not split_dir.is_dir():\n",
    "            continue\n",
    "        for vid_dir in split_dir.iterdir():\n",
    "            if vid_dir.is_dir():\n",
    "                whole_plan.extend(plan_segment_renames(vid_dir))\n",
    "\n",
    "    if not whole_plan:\n",
    "        print(\"Сегментов нет, нечего писать.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(whole_plan)\n",
    "    view = df[[\"video_id\", \"src\", \"dst_name\"]].sort_values([\"video_id\", \"dst_name\"])\n",
    "    print(\"\\nПлан (первые 20 строк):\")\n",
    "    print(view.head(20).to_string(index=False))\n",
    "\n",
    "    if not DRY_RUN:\n",
    "        execute_plan(whole_plan)\n",
    "\n",
    "    # CSV только с маппингом: video_id -> segment_file\n",
    "    mapping = df[[\"video_id\", \"dst_name\"]].rename(columns={\"dst_name\": \"segment_file\"})\n",
    "    mapping.to_csv(BASE / \"segments_map.csv\", index=False)\n",
    "    print(f\"\\nГотово. Маппинг сохранён в {BASE/'segments_map.csv'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4adba61d-e4f3-469d-acc0-60c8655d5ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Обработка dev_labels ===\n",
      "Сохранил E:\\WSM\\parkinson\\dev_labels_with_segments.csv (строк: 316)\n",
      "\n",
      "=== Обработка test_labels ===\n",
      "Сохранил E:\\WSM\\parkinson\\test_labels_with_segments.csv (строк: 545)\n",
      "\n",
      "=== Обработка train_labels ===\n",
      "Сохранил E:\\WSM\\parkinson\\train_labels_with_segments.csv (строк: 2789)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\parkinson\")\n",
    "SETS = [\"dev_labels\", \"test_labels\", \"train_labels\"]\n",
    "\n",
    "for split in SETS:\n",
    "    csv_path = BASE / f\"{split}.csv\"\n",
    "    dir_path = BASE / split\n",
    "\n",
    "    print(f\"\\n=== Обработка {split} ===\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    new_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        video_id = str(row[\"video_id\"])\n",
    "        seg_dir = dir_path / video_id / \"segments\"\n",
    "\n",
    "        if seg_dir.is_dir():\n",
    "            files = sorted(os.listdir(seg_dir))\n",
    "            for f in files:\n",
    "                new_row = row.copy()\n",
    "                new_row[\"segment_file\"] = f\n",
    "                new_rows.append(new_row)\n",
    "        else:\n",
    "            # нет сегментов — добавляем как есть (без segment_file)\n",
    "            new_row = row.copy()\n",
    "            new_row[\"segment_file\"] = None\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "    df_new = pd.DataFrame(new_rows)\n",
    "\n",
    "    # сохраняем как отдельный файл (чтобы не угробить оригинал)\n",
    "    out_path = BASE / f\"{split}_with_segments.csv\"\n",
    "    df_new.to_csv(out_path, index=False)\n",
    "    print(f\"Сохранил {out_path} (строк: {len(df_new)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f511db13-778e-4d55-88e1-54a716d6b79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранил E:\\WSM\\depression\\dev_labels_segments_min.csv (строк: 663)\n",
      "Сохранил E:\\WSM\\depression\\test_labels_segments_min.csv (строк: 881)\n",
      "Сохранил E:\\WSM\\depression\\train_labels_segments_min.csv (строк: 3832)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\depression\")\n",
    "SETS = [\"dev_labels\", \"test_labels\", \"train_labels\"]\n",
    "\n",
    "KEEP_COLS = [\"video_id\", \"diagnosis\", \"segment_file\"]\n",
    "\n",
    "for split in SETS:\n",
    "    in_path = BASE / f\"{split}_with_segments.csv\"\n",
    "    out_path = BASE / f\"{split}_segments_min.csv\"\n",
    "\n",
    "    df = pd.read_csv(in_path)\n",
    "\n",
    "    # оставляем только нужные колонки\n",
    "    cols_exist = [c for c in KEEP_COLS if c in df.columns]\n",
    "    df = df[cols_exist]\n",
    "\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Сохранил {out_path} (строк: {len(df)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78478795-2750-4ec5-aaf6-094e6b190ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранил E:\\WSM\\parkinson\\dev_labels_segments_min.csv (строк: 316)\n",
      "Сохранил E:\\WSM\\parkinson\\test_labels_segments_min.csv (строк: 545)\n",
      "Сохранил E:\\WSM\\parkinson\\train_labels_segments_min.csv (строк: 2789)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\parkinson\")\n",
    "SETS = [\"dev_labels\", \"test_labels\", \"train_labels\"]\n",
    "\n",
    "KEEP_COLS = [\"video_id\", \"diagnosis\", \"segment_file\"]\n",
    "\n",
    "for split in SETS:\n",
    "    in_path = BASE / f\"{split}_with_segments.csv\"\n",
    "    out_path = BASE / f\"{split}_segments_min.csv\"\n",
    "\n",
    "    df = pd.read_csv(in_path)\n",
    "\n",
    "    # оставляем только нужные колонки\n",
    "    cols_exist = [c for c in KEEP_COLS if c in df.columns]\n",
    "    df = df[cols_exist]\n",
    "\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Сохранил {out_path} (строк: {len(df)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aedc58b6-63a1-4e5d-b6ac-2bc00c3870c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Распределение по diagnosis депрессия:\n",
      "split      dev_labels_segments_min_filtered.csv  test_labels_segments_min_filtered.csv  train_labels_segments_min_filtered.csv\n",
      "diagnosis                                                                                                                     \n",
      "0                                           307                                    492                                    2284\n",
      "1                                           317                                    335                                    1431\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\depression\")\n",
    "SETS = [\"dev_labels_segments_min_filtered.csv\", \"test_labels_segments_min_filtered.csv\", \"train_labels_segments_min_filtered.csv\"]\n",
    "\n",
    "all_stats = []\n",
    "\n",
    "for fname in SETS:\n",
    "    path = BASE / fname\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    counts = df[\"diagnosis\"].value_counts().sort_index()\n",
    "    tmp = counts.reset_index()\n",
    "    tmp.columns = [\"diagnosis\", \"count\"]\n",
    "    tmp[\"split\"] = fname.replace(\"_segments_min.csv\", \"\")\n",
    "    all_stats.append(tmp)\n",
    "\n",
    "# объединяем\n",
    "df_stats = pd.concat(all_stats)\n",
    "\n",
    "# сводная таблица\n",
    "pivot = df_stats.pivot_table(\n",
    "    index=\"diagnosis\",\n",
    "    columns=\"split\",\n",
    "    values=\"count\",\n",
    "    fill_value=0,\n",
    "    aggfunc=\"sum\"\n",
    ")\n",
    "\n",
    "# делаем всё int\n",
    "pivot = pivot.astype(int)\n",
    "\n",
    "print(\"\\nРаспределение по diagnosis депрессия:\")\n",
    "print(pivot.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a188a30c-176b-406f-8298-fda1fd29bd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Распределение по diagnosis ПАРКИНСОН (считаем по уникальным video_id):\n",
      "split      dev_labels_segments_min_filtered  test_labels_segments_min_filtered  train_labels_segments_min_filtered\n",
      "diagnosis                                                                                                         \n",
      "0                                        22                                 25                                 132\n",
      "1                                        22                                 21                                 140\n",
      "total                                    44                                 46                                 272\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\parkinson\")\n",
    "SETS = [\"dev_labels_segments_min_filtered.csv\", \"test_labels_segments_min_filtered.csv\", \"train_labels_segments_min_filtered.csv\"]\n",
    "\n",
    "all_stats = []\n",
    "\n",
    "\n",
    "for fname in SETS:\n",
    "    path = BASE / fname\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # удаляем дубли по video_id (если вдруг есть)\n",
    "    df_unique = df.drop_duplicates(subset=[\"video_id\"])\n",
    "\n",
    "    counts = df_unique[\"diagnosis\"].value_counts().sort_index()\n",
    "    tmp = counts.reset_index()\n",
    "    tmp.columns = [\"diagnosis\", \"count\"]\n",
    "    tmp[\"split\"] = fname.replace(\".csv\", \"\")\n",
    "    all_stats.append(tmp)\n",
    "\n",
    "# объединяем\n",
    "df_stats = pd.concat(all_stats)\n",
    "\n",
    "# сводная таблица\n",
    "pivot = df_stats.pivot_table(\n",
    "    index=\"diagnosis\",\n",
    "    columns=\"split\",\n",
    "    values=\"count\",\n",
    "    fill_value=0,\n",
    "    aggfunc=\"sum\"\n",
    ")\n",
    "\n",
    "# int вместо float\n",
    "pivot = pivot.astype(int)\n",
    "\n",
    "# добавляем строку total (сумма по diagnosis)\n",
    "pivot.loc[\"total\"] = pivot.sum()\n",
    "\n",
    "print(\"\\nРаспределение по diagnosis ПАРКИНСОН (считаем по уникальным video_id):\")\n",
    "print(pivot.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2927a9d4-d147-4df8-8802-f7f33ae01b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Распределение по diagnosis DEPRESSION (считаем по уникальным video_id):\n",
      "split      dev_labels_segments_min_filtered  test_labels_segments_min_filtered  train_labels_segments_min_filtered\n",
      "diagnosis                                                                                                         \n",
      "0                                        29                                 27                                 156\n",
      "1                                        27                                 28                                 135\n",
      "total                                    56                                 55                                 291\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\depression\")\n",
    "SETS = [\"dev_labels_segments_min_filtered.csv\", \"test_labels_segments_min_filtered.csv\", \"train_labels_segments_min_filtered.csv\"]\n",
    "\n",
    "all_stats = []\n",
    "\n",
    "\n",
    "for fname in SETS:\n",
    "    path = BASE / fname\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # удаляем дубли по video_id (если вдруг есть)\n",
    "    df_unique = df.drop_duplicates(subset=[\"video_id\"])\n",
    "\n",
    "    counts = df_unique[\"diagnosis\"].value_counts().sort_index()\n",
    "    tmp = counts.reset_index()\n",
    "    tmp.columns = [\"diagnosis\", \"count\"]\n",
    "    tmp[\"split\"] = fname.replace(\".csv\", \"\")\n",
    "    all_stats.append(tmp)\n",
    "\n",
    "# объединяем\n",
    "df_stats = pd.concat(all_stats)\n",
    "\n",
    "# сводная таблица\n",
    "pivot = df_stats.pivot_table(\n",
    "    index=\"diagnosis\",\n",
    "    columns=\"split\",\n",
    "    values=\"count\",\n",
    "    fill_value=0,\n",
    "    aggfunc=\"sum\"\n",
    ")\n",
    "\n",
    "# int вместо float\n",
    "pivot = pivot.astype(int)\n",
    "\n",
    "# добавляем строку total (сумма по diagnosis)\n",
    "pivot.loc[\"total\"] = pivot.sum()\n",
    "\n",
    "print(\"\\nРаспределение по diagnosis DEPRESSION (считаем по уникальным video_id):\")\n",
    "print(pivot.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f2a8bf2-b70b-4b57-9bb0-545de0a31f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сводка по чистке A на основе B:\n",
      "            metric  value\n",
      "   unique_ids_in_A     47\n",
      "   unique_ids_in_B     44\n",
      "ids_removed_from_A      3\n",
      "  rows_in_A_before    316\n",
      "   rows_in_A_after    312\n",
      "      rows_removed      4\n",
      "\n",
      "Первые 3 ID, которых НЕТ в B и которые будут удалены из A:\n",
      "87mxEmx7zeA\n",
      "NUeEFVy2Ojw\n",
      "U74-VmwOeGI\n",
      "\n",
      "Сохранено: E:\\WSM\\parkinson\\dev_labels_segments_min_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\parkinson\")\n",
    "\n",
    "# 👉 УКАЖИ свои файлы\n",
    "FILE_A = BASE / \"dev_labels_segments_min.csv\"      # файл со строками по сегментам (много строк на 1 video_id)\n",
    "FILE_B = BASE / \"dev_w_fe_vid.csv\"            # файл-эталон с уникальными video_id\n",
    "\n",
    "SAVE = True  # True — сохранить отфильтрованный A в новый CSV\n",
    "\n",
    "# 1) читаем и приводим video_id к строке\n",
    "df_a = pd.read_csv(FILE_A)\n",
    "df_b = pd.read_csv(FILE_B)\n",
    "\n",
    "df_a[\"video_id\"] = df_a[\"video_id\"].astype(str)\n",
    "df_b[\"video_id\"] = df_b[\"video_id\"].astype(str)\n",
    "\n",
    "# 2) множество валидных ID из файла B (уникальные)\n",
    "ids_b = set(df_b[\"video_id\"].unique())\n",
    "\n",
    "# 3) что есть в A\n",
    "ids_a = set(df_a[\"video_id\"].unique())\n",
    "\n",
    "# 4) кого нужно удалить из A (в A есть, в B нет)\n",
    "ids_to_drop = sorted(ids_a - ids_b)\n",
    "\n",
    "# 5) фильтруем A, оставляя только тех, кто есть в B\n",
    "mask = df_a[\"video_id\"].isin(ids_b)\n",
    "df_a_filtered = df_a[mask].copy()\n",
    "\n",
    "# 6) мини-отчёт\n",
    "report = pd.DataFrame({\n",
    "    \"metric\": [\n",
    "        \"unique_ids_in_A\",\n",
    "        \"unique_ids_in_B\",\n",
    "        \"ids_removed_from_A\",\n",
    "        \"rows_in_A_before\",\n",
    "        \"rows_in_A_after\",\n",
    "        \"rows_removed\"\n",
    "    ],\n",
    "    \"value\": [\n",
    "        len(ids_a),\n",
    "        len(ids_b),\n",
    "        len(ids_to_drop),\n",
    "        len(df_a),\n",
    "        len(df_a_filtered),\n",
    "        len(df_a) - len(df_a_filtered)\n",
    "    ]\n",
    "})\n",
    "print(\"\\nСводка по чистке A на основе B:\")\n",
    "print(report.to_string(index=False))\n",
    "\n",
    "# 7) покажем первые N удаляемых ID (чтобы глазами проверить)\n",
    "N = 20\n",
    "if ids_to_drop:\n",
    "    print(f\"\\nПервые {min(N, len(ids_to_drop))} ID, которых НЕТ в B и которые будут удалены из A:\")\n",
    "    print(pd.Series(ids_to_drop[:N]).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nУдалять по ID нечего — всё из A присутствует в B. На этот раз ты справился :)\")\n",
    "\n",
    "# 8) сохранение по желанию\n",
    "if SAVE:\n",
    "    out_path = FILE_A.with_name(FILE_A.stem + \"_filtered.csv\")\n",
    "    df_a_filtered.to_csv(out_path, index=False)\n",
    "    print(f\"\\nСохранено: {out_path}\")\n",
    "else:\n",
    "    print(\"\\nSAVE=False — ничего не сохраняю. Возьми df_a_filtered из памяти, если запускаешь в ноутбуке.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4755dfa4-a9ea-46e3-9079-b8dfbff7a336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Уникальные video_id в test_labels_segments_min_filtered.csv: 46\n",
      "Уникальные video_id в test_w_fe_vid.csv: 46\n",
      "\n",
      "IDs из test_labels_segments_min_filtered.csv, которых нет в test_w_fe_vid.csv (0):\n",
      "[]\n",
      "\n",
      "IDs из test_w_fe_vid.csv, которых нет в test_labels_segments_min_filtered.csv (0):\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\parkinson\")\n",
    "\n",
    "# какие два файла сравниваем\n",
    "FILE_A = BASE / \"test_labels_segments_min_filtered.csv\"\n",
    "FILE_B = BASE / \"test_w_fe_vid.csv\"\n",
    "\n",
    "# читаем уникальные video_id\n",
    "ids_a = set(pd.read_csv(FILE_A)[\"video_id\"].astype(str).unique())\n",
    "ids_b = set(pd.read_csv(FILE_B)[\"video_id\"].astype(str).unique())\n",
    "\n",
    "# разности\n",
    "missing_in_b = sorted(ids_a - ids_b)\n",
    "missing_in_a = sorted(ids_b - ids_a)\n",
    "\n",
    "print(f\"\\nУникальные video_id в {FILE_A.name}: {len(ids_a)}\")\n",
    "print(f\"Уникальные video_id в {FILE_B.name}: {len(ids_b)}\")\n",
    "\n",
    "print(f\"\\nIDs из {FILE_A.name}, которых нет в {FILE_B.name} ({len(missing_in_b)}):\")\n",
    "print(missing_in_b[:20])  # первые 20\n",
    "\n",
    "print(f\"\\nIDs из {FILE_B.name}, которых нет в {FILE_A.name} ({len(missing_in_a)}):\")\n",
    "print(missing_in_a[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d04fd088-6109-4be9-afde-dd9060b630c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Распределение по diagnosis ПАРКИНСОН (по уникальным video_id):\n",
      "split      dev_labels_segments_min_filtered  test_labels_segments_min_filtered  train_labels_segments_min_filtered\n",
      "diagnosis                                                                                                         \n",
      "0                                        22                                 25                                 132\n",
      "1                                        22                                 21                                 140\n",
      "total                                    44                                 46                                 272\n",
      "\n",
      "Распределение по diagnosis ПАРКИНСОН (по всем строкам / сегментам):\n",
      "split      dev_labels_segments_min_filtered  test_labels_segments_min_filtered  train_labels_segments_min_filtered\n",
      "diagnosis                                                                                                         \n",
      "0                                       207                                404                                1678\n",
      "1                                       105                                133                                1058\n",
      "total                                   312                                537                                2736\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\parkinson\")\n",
    "SETS = [\n",
    "    \"dev_labels_segments_min_filtered.csv\",\n",
    "    \"test_labels_segments_min_filtered.csv\",\n",
    "    \"train_labels_segments_min_filtered.csv\"\n",
    "]\n",
    "\n",
    "# ===== по уникальным video_id =====\n",
    "all_stats_unique = []\n",
    "\n",
    "for fname in SETS:\n",
    "    path = BASE / fname\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # оставляем только уникальные video_id\n",
    "    df_unique = df.drop_duplicates(subset=[\"video_id\"])\n",
    "\n",
    "    counts = df_unique[\"diagnosis\"].value_counts().sort_index()\n",
    "    tmp = counts.reset_index()\n",
    "    tmp.columns = [\"diagnosis\", \"count\"]\n",
    "    tmp[\"split\"] = fname.replace(\".csv\", \"\")\n",
    "    all_stats_unique.append(tmp)\n",
    "\n",
    "df_stats_unique = pd.concat(all_stats_unique)\n",
    "\n",
    "pivot_unique = df_stats_unique.pivot_table(\n",
    "    index=\"diagnosis\",\n",
    "    columns=\"split\",\n",
    "    values=\"count\",\n",
    "    fill_value=0,\n",
    "    aggfunc=\"sum\"\n",
    ").astype(int)\n",
    "\n",
    "pivot_unique.loc[\"total\"] = pivot_unique.sum()\n",
    "\n",
    "print(\"\\nРаспределение по diagnosis ПАРКИНСОН (по уникальным video_id):\")\n",
    "print(pivot_unique.to_string())\n",
    "\n",
    "# ===== по всем строкам (сегментам) =====\n",
    "all_stats_all = []\n",
    "\n",
    "for fname in SETS:\n",
    "    path = BASE / fname\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    counts = df[\"diagnosis\"].value_counts().sort_index()\n",
    "    tmp = counts.reset_index()\n",
    "    tmp.columns = [\"diagnosis\", \"count\"]\n",
    "    tmp[\"split\"] = fname.replace(\".csv\", \"\")\n",
    "    all_stats_all.append(tmp)\n",
    "\n",
    "df_stats_all = pd.concat(all_stats_all)\n",
    "\n",
    "pivot_all = df_stats_all.pivot_table(\n",
    "    index=\"diagnosis\",\n",
    "    columns=\"split\",\n",
    "    values=\"count\",\n",
    "    fill_value=0,\n",
    "    aggfunc=\"sum\"\n",
    ").astype(int)\n",
    "\n",
    "pivot_all.loc[\"total\"] = pivot_all.sum()\n",
    "\n",
    "print(\"\\nРаспределение по diagnosis ПАРКИНСОН (по всем строкам / сегментам):\")\n",
    "print(pivot_all.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6fdd70fa-c488-46e5-bc8e-48c72cf039d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Распределение по diagnosis ДЕПРЕССИЯ (по уникальным video_id):\n",
      "split      dev_labels_segments_min_filtered  test_labels_segments_min_filtered  train_labels_segments_min_filtered\n",
      "diagnosis                                                                                                         \n",
      "0                                        29                                 27                                 156\n",
      "1                                        27                                 28                                 135\n",
      "total                                    56                                 55                                 291\n",
      "\n",
      "Распределение по diagnosis ДЕПРЕССИЯ (по всем строкам / сегментам):\n",
      "split      dev_labels_segments_min_filtered  test_labels_segments_min_filtered  train_labels_segments_min_filtered\n",
      "diagnosis                                                                                                         \n",
      "0                                       307                                492                                2284\n",
      "1                                       317                                335                                1431\n",
      "total                                   624                                827                                3715\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\depression\")\n",
    "SETS = [\n",
    "    \"dev_labels_segments_min_filtered.csv\",\n",
    "    \"test_labels_segments_min_filtered.csv\",\n",
    "    \"train_labels_segments_min_filtered.csv\"\n",
    "]\n",
    "\n",
    "# ===== по уникальным video_id =====\n",
    "all_stats_unique = []\n",
    "\n",
    "for fname in SETS:\n",
    "    path = BASE / fname\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # оставляем только уникальные video_id\n",
    "    df_unique = df.drop_duplicates(subset=[\"video_id\"])\n",
    "\n",
    "    counts = df_unique[\"diagnosis\"].value_counts().sort_index()\n",
    "    tmp = counts.reset_index()\n",
    "    tmp.columns = [\"diagnosis\", \"count\"]\n",
    "    tmp[\"split\"] = fname.replace(\".csv\", \"\")\n",
    "    all_stats_unique.append(tmp)\n",
    "\n",
    "df_stats_unique = pd.concat(all_stats_unique)\n",
    "\n",
    "pivot_unique = df_stats_unique.pivot_table(\n",
    "    index=\"diagnosis\",\n",
    "    columns=\"split\",\n",
    "    values=\"count\",\n",
    "    fill_value=0,\n",
    "    aggfunc=\"sum\"\n",
    ").astype(int)\n",
    "\n",
    "pivot_unique.loc[\"total\"] = pivot_unique.sum()\n",
    "\n",
    "print(\"\\nРаспределение по diagnosis ДЕПРЕССИЯ (по уникальным video_id):\")\n",
    "print(pivot_unique.to_string())\n",
    "\n",
    "# ===== по всем строкам (сегментам) =====\n",
    "all_stats_all = []\n",
    "\n",
    "for fname in SETS:\n",
    "    path = BASE / fname\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    counts = df[\"diagnosis\"].value_counts().sort_index()\n",
    "    tmp = counts.reset_index()\n",
    "    tmp.columns = [\"diagnosis\", \"count\"]\n",
    "    tmp[\"split\"] = fname.replace(\".csv\", \"\")\n",
    "    all_stats_all.append(tmp)\n",
    "\n",
    "df_stats_all = pd.concat(all_stats_all)\n",
    "\n",
    "pivot_all = df_stats_all.pivot_table(\n",
    "    index=\"diagnosis\",\n",
    "    columns=\"split\",\n",
    "    values=\"count\",\n",
    "    fill_value=0,\n",
    "    aggfunc=\"sum\"\n",
    ").astype(int)\n",
    "\n",
    "pivot_all.loc[\"total\"] = pivot_all.sum()\n",
    "\n",
    "print(\"\\nРаспределение по diagnosis ДЕПРЕССИЯ (по всем строкам / сегментам):\")\n",
    "print(pivot_all.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3d1a58-8278-447d-a733-684103a6673e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
