{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "451aa704-a91e-4ca0-bb4e-1ab57b4a6c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–ü–ª–∞–Ω (–ø–µ—Ä–≤—ã–µ 20 —Å—Ç—Ä–æ–∫):\n",
      "   video_id                                                                     src            dst_name\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_001.mp4 -7UpRmNVJzQ_001.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_002.mp4 -7UpRmNVJzQ_002.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_003.mp4 -7UpRmNVJzQ_003.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_004.mp4 -7UpRmNVJzQ_004.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_005.mp4 -7UpRmNVJzQ_005.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_006.mp4 -7UpRmNVJzQ_006.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_007.mp4 -7UpRmNVJzQ_007.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_008.mp4 -7UpRmNVJzQ_008.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_009.mp4 -7UpRmNVJzQ_009.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_010.mp4 -7UpRmNVJzQ_010.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_011.mp4 -7UpRmNVJzQ_011.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_012.mp4 -7UpRmNVJzQ_012.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_013.mp4 -7UpRmNVJzQ_013.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_014.mp4 -7UpRmNVJzQ_014.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_015.mp4 -7UpRmNVJzQ_015.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_016.mp4 -7UpRmNVJzQ_016.mp4\n",
      "-7UpRmNVJzQ E:\\WSM\\depression\\train_labels\\-7UpRmNVJzQ\\segments\\-7UpRmNVJzQ_017.mp4 -7UpRmNVJzQ_017.mp4\n",
      "0FbNUlG6xpg E:\\WSM\\depression\\train_labels\\0FbNUlG6xpg\\segments\\0FbNUlG6xpg_001.mp4 0FbNUlG6xpg_001.mp4\n",
      "0FbNUlG6xpg E:\\WSM\\depression\\train_labels\\0FbNUlG6xpg\\segments\\0FbNUlG6xpg_002.mp4 0FbNUlG6xpg_002.mp4\n",
      "0FbNUlG6xpg E:\\WSM\\depression\\train_labels\\0FbNUlG6xpg\\segments\\0FbNUlG6xpg_003.mp4 0FbNUlG6xpg_003.mp4\n",
      "\n",
      "–ì–æ—Ç–æ–≤–æ. –ú–∞–ø–ø–∏–Ω–≥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ E:\\WSM\\depression\\segments_map.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\depression\")\n",
    "LIST_SETS = [\"dev_labels\", \"test_labels\", \"train_labels\"]\n",
    "VIDEO_EXTS = {\".mp4\", \".avi\", \".mov\", \".mkv\", \".wmv\", \".mpg\", \".mpeg\", \".m4v\", \".flv\", \".webm\", \".wav\"}\n",
    "DRY_RUN = True  # False = —Ä–µ–∞–ª—å–Ω–æ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å\n",
    "\n",
    "def natural_key(s: str):\n",
    "    return [int(t) if t.isdigit() else t.lower() for t in re.findall(r'\\d+|\\D+', s)]\n",
    "\n",
    "def plan_segment_renames(vid_dir: Path):\n",
    "    seg_dir = vid_dir / \"segments\"\n",
    "    if not seg_dir.is_dir():\n",
    "        return []\n",
    "\n",
    "    files = [p for p in seg_dir.iterdir() if p.is_file() and p.suffix.lower() in VIDEO_EXTS]\n",
    "    if not files:\n",
    "        return []\n",
    "\n",
    "    files_sorted = sorted(files, key=lambda p: natural_key(p.name))\n",
    "    pad = max(3, len(str(len(files_sorted))))\n",
    "\n",
    "    video_id = vid_dir.name\n",
    "    plan = []\n",
    "    for i, src in enumerate(files_sorted, 1):\n",
    "        dst_name = f\"{video_id}_{str(i).zfill(pad)}{src.suffix.lower()}\"\n",
    "        dst = src.with_name(dst_name)\n",
    "        plan.append({\n",
    "            \"video_id\": video_id,\n",
    "            \"src\": str(src),\n",
    "            \"dst\": str(dst),\n",
    "            \"dst_name\": dst_name\n",
    "        })\n",
    "    return plan\n",
    "\n",
    "def execute_plan(rows):\n",
    "    for r in rows:\n",
    "        src = Path(r[\"src\"])\n",
    "        dst = Path(r[\"dst\"])\n",
    "        if src.exists() and src.name != dst.name:\n",
    "            src.rename(dst)\n",
    "\n",
    "def main():\n",
    "    whole_plan = []\n",
    "    for split in LIST_SETS:\n",
    "        split_dir = BASE / split\n",
    "        if not split_dir.is_dir():\n",
    "            continue\n",
    "        for vid_dir in split_dir.iterdir():\n",
    "            if vid_dir.is_dir():\n",
    "                whole_plan.extend(plan_segment_renames(vid_dir))\n",
    "\n",
    "    if not whole_plan:\n",
    "        print(\"–°–µ–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç, –Ω–µ—á–µ–≥–æ –ø–∏—Å–∞—Ç—å.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(whole_plan)\n",
    "    view = df[[\"video_id\", \"src\", \"dst_name\"]].sort_values([\"video_id\", \"dst_name\"])\n",
    "    print(\"\\n–ü–ª–∞–Ω (–ø–µ—Ä–≤—ã–µ 20 —Å—Ç—Ä–æ–∫):\")\n",
    "    print(view.head(20).to_string(index=False))\n",
    "\n",
    "    if not DRY_RUN:\n",
    "        execute_plan(whole_plan)\n",
    "\n",
    "    # CSV —Ç–æ–ª—å–∫–æ —Å –º–∞–ø–ø–∏–Ω–≥–æ–º: video_id -> segment_file\n",
    "    mapping = df[[\"video_id\", \"dst_name\"]].rename(columns={\"dst_name\": \"segment_file\"})\n",
    "    mapping.to_csv(BASE / \"segments_map.csv\", index=False)\n",
    "    print(f\"\\n–ì–æ—Ç–æ–≤–æ. –ú–∞–ø–ø–∏–Ω–≥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {BASE/'segments_map.csv'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be8b7fc-d52a-4f01-a1b1-c71b76f18f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf40838c-e8ce-4737-a135-505b1ec4ec49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== –û–±—Ä–∞–±–æ—Ç–∫–∞ dev_labels ===\n",
      "–°–æ—Ö—Ä–∞–Ω–∏–ª E:\\WSM\\depression\\dev_labels_with_segments.csv (—Å—Ç—Ä–æ–∫: 663)\n",
      "\n",
      "=== –û–±—Ä–∞–±–æ—Ç–∫–∞ test_labels ===\n",
      "–°–æ—Ö—Ä–∞–Ω–∏–ª E:\\WSM\\depression\\test_labels_with_segments.csv (—Å—Ç—Ä–æ–∫: 881)\n",
      "\n",
      "=== –û–±—Ä–∞–±–æ—Ç–∫–∞ train_labels ===\n",
      "–°–æ—Ö—Ä–∞–Ω–∏–ª E:\\WSM\\depression\\train_labels_with_segments.csv (—Å—Ç—Ä–æ–∫: 3832)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\depression\")\n",
    "SETS = [\"dev_labels\", \"test_labels\", \"train_labels\"]\n",
    "\n",
    "for split in SETS:\n",
    "    csv_path = BASE / f\"{split}.csv\"\n",
    "    dir_path = BASE / split\n",
    "\n",
    "    print(f\"\\n=== –û–±—Ä–∞–±–æ—Ç–∫–∞ {split} ===\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    new_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        video_id = str(row[\"video_id\"])\n",
    "        seg_dir = dir_path / video_id / \"segments\"\n",
    "\n",
    "        if seg_dir.is_dir():\n",
    "            files = sorted(os.listdir(seg_dir))\n",
    "            for f in files:\n",
    "                new_row = row.copy()\n",
    "                new_row[\"segment_file\"] = f\n",
    "                new_rows.append(new_row)\n",
    "        else:\n",
    "            # –Ω–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤ ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å (–±–µ–∑ segment_file)\n",
    "            new_row = row.copy()\n",
    "            new_row[\"segment_file\"] = None\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "    df_new = pd.DataFrame(new_rows)\n",
    "\n",
    "    # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª (—á—Ç–æ–±—ã –Ω–µ —É–≥—Ä–æ–±–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª)\n",
    "    out_path = BASE / f\"{split}_with_segments.csv\"\n",
    "    df_new.to_csv(out_path, index=False)\n",
    "    print(f\"–°–æ—Ö—Ä–∞–Ω–∏–ª {out_path} (—Å—Ç—Ä–æ–∫: {len(df_new)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a46ef8e0-5419-40ce-8fe6-49246ef87dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–ü–ª–∞–Ω (–ø–µ—Ä–≤—ã–µ 20 —Å—Ç—Ä–æ–∫):\n",
      "   video_id                                                                                                                                    src            dst_name\n",
      "3MKVlrQoHD4       E:\\WSM\\parkinson\\dev_labels\\3MKVlrQoHD4\\segments\\Can Microdosing Psilocybin Magic Mushrooms help with Parkinsons disease_000.mp4 3MKVlrQoHD4_001.mp4\n",
      "3MKVlrQoHD4       E:\\WSM\\parkinson\\dev_labels\\3MKVlrQoHD4\\segments\\Can Microdosing Psilocybin Magic Mushrooms help with Parkinsons disease_001.mp4 3MKVlrQoHD4_002.mp4\n",
      "3MKVlrQoHD4       E:\\WSM\\parkinson\\dev_labels\\3MKVlrQoHD4\\segments\\Can Microdosing Psilocybin Magic Mushrooms help with Parkinsons disease_002.mp4 3MKVlrQoHD4_003.mp4\n",
      "3MKVlrQoHD4       E:\\WSM\\parkinson\\dev_labels\\3MKVlrQoHD4\\segments\\Can Microdosing Psilocybin Magic Mushrooms help with Parkinsons disease_003.mp4 3MKVlrQoHD4_004.mp4\n",
      "3MKVlrQoHD4       E:\\WSM\\parkinson\\dev_labels\\3MKVlrQoHD4\\segments\\Can Microdosing Psilocybin Magic Mushrooms help with Parkinsons disease_004.mp4 3MKVlrQoHD4_005.mp4\n",
      "3bHJDSws_jQ E:\\WSM\\parkinson\\dev_labels\\3bHJDSws_jQ\\segments\\Update on my 24 Hour Water Fast Living with Parkinsons Disease & Lyme Disease_000.mp4 3bHJDSws_jQ_001.mp4\n",
      "3bHJDSws_jQ E:\\WSM\\parkinson\\dev_labels\\3bHJDSws_jQ\\segments\\Update on my 24 Hour Water Fast Living with Parkinsons Disease & Lyme Disease_001.mp4 3bHJDSws_jQ_002.mp4\n",
      "3bHJDSws_jQ E:\\WSM\\parkinson\\dev_labels\\3bHJDSws_jQ\\segments\\Update on my 24 Hour Water Fast Living with Parkinsons Disease & Lyme Disease_002.mp4 3bHJDSws_jQ_003.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_000.mp4 4-d_F3MczUE_001.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_001.mp4 4-d_F3MczUE_002.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_002.mp4 4-d_F3MczUE_003.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_003.mp4 4-d_F3MczUE_004.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_004.mp4 4-d_F3MczUE_005.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_005.mp4 4-d_F3MczUE_006.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_006.mp4 4-d_F3MczUE_007.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_007.mp4 4-d_F3MczUE_008.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_008.mp4 4-d_F3MczUE_009.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_009.mp4 4-d_F3MczUE_010.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_010.mp4 4-d_F3MczUE_011.mp4\n",
      "4-d_F3MczUE                                              E:\\WSM\\parkinson\\dev_labels\\4-d_F3MczUE\\segments\\How I Deal With Hair Loss64 Plus_011.mp4 4-d_F3MczUE_012.mp4\n",
      "\n",
      "–ì–æ—Ç–æ–≤–æ. –ú–∞–ø–ø–∏–Ω–≥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ E:\\WSM\\parkinson\\segments_map.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\parkinson\")\n",
    "LIST_SETS = [\"dev_labels\"]\n",
    "VIDEO_EXTS = {\".mp4\", \".avi\", \".mov\", \".mkv\", \".wmv\", \".mpg\", \".mpeg\", \".m4v\", \".flv\", \".webm\", \".wav\"}\n",
    "DRY_RUN = False  # False = —Ä–µ–∞–ª—å–Ω–æ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å\n",
    "\n",
    "def natural_key(s: str):\n",
    "    return [int(t) if t.isdigit() else t.lower() for t in re.findall(r'\\d+|\\D+', s)]\n",
    "\n",
    "def plan_segment_renames(vid_dir: Path):\n",
    "    seg_dir = vid_dir / \"segments\"\n",
    "    if not seg_dir.is_dir():\n",
    "        return []\n",
    "\n",
    "    files = [p for p in seg_dir.iterdir() if p.is_file() and p.suffix.lower() in VIDEO_EXTS]\n",
    "    if not files:\n",
    "        return []\n",
    "\n",
    "    files_sorted = sorted(files, key=lambda p: natural_key(p.name))\n",
    "    pad = max(3, len(str(len(files_sorted))))\n",
    "\n",
    "    video_id = vid_dir.name\n",
    "    plan = []\n",
    "    for i, src in enumerate(files_sorted, 1):\n",
    "        dst_name = f\"{video_id}_{str(i).zfill(pad)}{src.suffix.lower()}\"\n",
    "        dst = src.with_name(dst_name)\n",
    "        plan.append({\n",
    "            \"video_id\": video_id,\n",
    "            \"src\": str(src),\n",
    "            \"dst\": str(dst),\n",
    "            \"dst_name\": dst_name\n",
    "        })\n",
    "    return plan\n",
    "\n",
    "def execute_plan(rows):\n",
    "    for r in rows:\n",
    "        src = Path(r[\"src\"])\n",
    "        dst = Path(r[\"dst\"])\n",
    "        if src.exists() and src.name != dst.name:\n",
    "            src.rename(dst)\n",
    "\n",
    "def main():\n",
    "    whole_plan = []\n",
    "    for split in LIST_SETS:\n",
    "        split_dir = BASE / split\n",
    "        if not split_dir.is_dir():\n",
    "            continue\n",
    "        for vid_dir in split_dir.iterdir():\n",
    "            if vid_dir.is_dir():\n",
    "                whole_plan.extend(plan_segment_renames(vid_dir))\n",
    "\n",
    "    if not whole_plan:\n",
    "        print(\"–°–µ–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç, –Ω–µ—á–µ–≥–æ –ø–∏—Å–∞—Ç—å.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(whole_plan)\n",
    "    view = df[[\"video_id\", \"src\", \"dst_name\"]].sort_values([\"video_id\", \"dst_name\"])\n",
    "    print(\"\\n–ü–ª–∞–Ω (–ø–µ—Ä–≤—ã–µ 20 —Å—Ç—Ä–æ–∫):\")\n",
    "    print(view.head(20).to_string(index=False))\n",
    "\n",
    "    if not DRY_RUN:\n",
    "        execute_plan(whole_plan)\n",
    "\n",
    "    # CSV —Ç–æ–ª—å–∫–æ —Å –º–∞–ø–ø–∏–Ω–≥–æ–º: video_id -> segment_file\n",
    "    mapping = df[[\"video_id\", \"dst_name\"]].rename(columns={\"dst_name\": \"segment_file\"})\n",
    "    mapping.to_csv(BASE / \"segments_map.csv\", index=False)\n",
    "    print(f\"\\n–ì–æ—Ç–æ–≤–æ. –ú–∞–ø–ø–∏–Ω–≥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {BASE/'segments_map.csv'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4adba61d-e4f3-469d-acc0-60c8655d5ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== –û–±—Ä–∞–±–æ—Ç–∫–∞ dev_labels ===\n",
      "–°–æ—Ö—Ä–∞–Ω–∏–ª E:\\WSM\\parkinson\\dev_labels_with_segments.csv (—Å—Ç—Ä–æ–∫: 316)\n",
      "\n",
      "=== –û–±—Ä–∞–±–æ—Ç–∫–∞ test_labels ===\n",
      "–°–æ—Ö—Ä–∞–Ω–∏–ª E:\\WSM\\parkinson\\test_labels_with_segments.csv (—Å—Ç—Ä–æ–∫: 545)\n",
      "\n",
      "=== –û–±—Ä–∞–±–æ—Ç–∫–∞ train_labels ===\n",
      "–°–æ—Ö—Ä–∞–Ω–∏–ª E:\\WSM\\parkinson\\train_labels_with_segments.csv (—Å—Ç—Ä–æ–∫: 2789)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\parkinson\")\n",
    "SETS = [\"dev_labels\", \"test_labels\", \"train_labels\"]\n",
    "\n",
    "for split in SETS:\n",
    "    csv_path = BASE / f\"{split}.csv\"\n",
    "    dir_path = BASE / split\n",
    "\n",
    "    print(f\"\\n=== –û–±—Ä–∞–±–æ—Ç–∫–∞ {split} ===\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    new_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        video_id = str(row[\"video_id\"])\n",
    "        seg_dir = dir_path / video_id / \"segments\"\n",
    "\n",
    "        if seg_dir.is_dir():\n",
    "            files = sorted(os.listdir(seg_dir))\n",
    "            for f in files:\n",
    "                new_row = row.copy()\n",
    "                new_row[\"segment_file\"] = f\n",
    "                new_rows.append(new_row)\n",
    "        else:\n",
    "            # –Ω–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤ ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å (–±–µ–∑ segment_file)\n",
    "            new_row = row.copy()\n",
    "            new_row[\"segment_file\"] = None\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "    df_new = pd.DataFrame(new_rows)\n",
    "\n",
    "    # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª (—á—Ç–æ–±—ã –Ω–µ —É–≥—Ä–æ–±–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª)\n",
    "    out_path = BASE / f\"{split}_with_segments.csv\"\n",
    "    df_new.to_csv(out_path, index=False)\n",
    "    print(f\"–°–æ—Ö—Ä–∞–Ω–∏–ª {out_path} (—Å—Ç—Ä–æ–∫: {len(df_new)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f511db13-778e-4d55-88e1-54a716d6b79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–æ—Ö—Ä–∞–Ω–∏–ª E:\\WSM\\depression\\dev_labels_segments_min.csv (—Å—Ç—Ä–æ–∫: 663)\n",
      "–°–æ—Ö—Ä–∞–Ω–∏–ª E:\\WSM\\depression\\test_labels_segments_min.csv (—Å—Ç—Ä–æ–∫: 881)\n",
      "–°–æ—Ö—Ä–∞–Ω–∏–ª E:\\WSM\\depression\\train_labels_segments_min.csv (—Å—Ç—Ä–æ–∫: 3832)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\depression\")\n",
    "SETS = [\"dev_labels\", \"test_labels\", \"train_labels\"]\n",
    "\n",
    "KEEP_COLS = [\"video_id\", \"diagnosis\", \"segment_file\"]\n",
    "\n",
    "for split in SETS:\n",
    "    in_path = BASE / f\"{split}_with_segments.csv\"\n",
    "    out_path = BASE / f\"{split}_segments_min.csv\"\n",
    "\n",
    "    df = pd.read_csv(in_path)\n",
    "\n",
    "    # –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "    cols_exist = [c for c in KEEP_COLS if c in df.columns]\n",
    "    df = df[cols_exist]\n",
    "\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"–°–æ—Ö—Ä–∞–Ω–∏–ª {out_path} (—Å—Ç—Ä–æ–∫: {len(df)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78478795-2750-4ec5-aaf6-094e6b190ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–æ—Ö—Ä–∞–Ω–∏–ª E:\\WSM\\parkinson\\dev_labels_segments_min.csv (—Å—Ç—Ä–æ–∫: 316)\n",
      "–°–æ—Ö—Ä–∞–Ω–∏–ª E:\\WSM\\parkinson\\test_labels_segments_min.csv (—Å—Ç—Ä–æ–∫: 545)\n",
      "–°–æ—Ö—Ä–∞–Ω–∏–ª E:\\WSM\\parkinson\\train_labels_segments_min.csv (—Å—Ç—Ä–æ–∫: 2789)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\parkinson\")\n",
    "SETS = [\"dev_labels\", \"test_labels\", \"train_labels\"]\n",
    "\n",
    "KEEP_COLS = [\"video_id\", \"diagnosis\", \"segment_file\"]\n",
    "\n",
    "for split in SETS:\n",
    "    in_path = BASE / f\"{split}_with_segments.csv\"\n",
    "    out_path = BASE / f\"{split}_segments_min.csv\"\n",
    "\n",
    "    df = pd.read_csv(in_path)\n",
    "\n",
    "    # –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "    cols_exist = [c for c in KEEP_COLS if c in df.columns]\n",
    "    df = df[cols_exist]\n",
    "\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"–°–æ—Ö—Ä–∞–Ω–∏–ª {out_path} (—Å—Ç—Ä–æ–∫: {len(df)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aedc58b6-63a1-4e5d-b6ac-2bc00c3870c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ diagnosis –¥–µ–ø—Ä–µ—Å—Å–∏—è:\n",
      "split      dev_labels_segments_min_filtered.csv  test_labels_segments_min_filtered.csv  train_labels_segments_min_filtered.csv\n",
      "diagnosis                                                                                                                     \n",
      "0                                           307                                    492                                    2284\n",
      "1                                           317                                    335                                    1431\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\depression\")\n",
    "SETS = [\"dev_labels_segments_min_filtered.csv\", \"test_labels_segments_min_filtered.csv\", \"train_labels_segments_min_filtered.csv\"]\n",
    "\n",
    "all_stats = []\n",
    "\n",
    "for fname in SETS:\n",
    "    path = BASE / fname\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    counts = df[\"diagnosis\"].value_counts().sort_index()\n",
    "    tmp = counts.reset_index()\n",
    "    tmp.columns = [\"diagnosis\", \"count\"]\n",
    "    tmp[\"split\"] = fname.replace(\"_segments_min.csv\", \"\")\n",
    "    all_stats.append(tmp)\n",
    "\n",
    "# –æ–±—ä–µ–¥–∏–Ω—è–µ–º\n",
    "df_stats = pd.concat(all_stats)\n",
    "\n",
    "# —Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞\n",
    "pivot = df_stats.pivot_table(\n",
    "    index=\"diagnosis\",\n",
    "    columns=\"split\",\n",
    "    values=\"count\",\n",
    "    fill_value=0,\n",
    "    aggfunc=\"sum\"\n",
    ")\n",
    "\n",
    "# –¥–µ–ª–∞–µ–º –≤—Å—ë int\n",
    "pivot = pivot.astype(int)\n",
    "\n",
    "print(\"\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ diagnosis –¥–µ–ø—Ä–µ—Å—Å–∏—è:\")\n",
    "print(pivot.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a188a30c-176b-406f-8298-fda1fd29bd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ diagnosis –ü–ê–†–ö–ò–ù–°–û–ù (—Å—á–∏—Ç–∞–µ–º –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º video_id):\n",
      "split      dev_labels_segments_min_filtered  test_labels_segments_min_filtered  train_labels_segments_min_filtered\n",
      "diagnosis                                                                                                         \n",
      "0                                        22                                 25                                 132\n",
      "1                                        22                                 21                                 140\n",
      "total                                    44                                 46                                 272\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\parkinson\")\n",
    "SETS = [\"dev_labels_segments_min_filtered.csv\", \"test_labels_segments_min_filtered.csv\", \"train_labels_segments_min_filtered.csv\"]\n",
    "\n",
    "all_stats = []\n",
    "\n",
    "\n",
    "for fname in SETS:\n",
    "    path = BASE / fname\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # —É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏ –ø–æ video_id (–µ—Å–ª–∏ –≤–¥—Ä—É–≥ –µ—Å—Ç—å)\n",
    "    df_unique = df.drop_duplicates(subset=[\"video_id\"])\n",
    "\n",
    "    counts = df_unique[\"diagnosis\"].value_counts().sort_index()\n",
    "    tmp = counts.reset_index()\n",
    "    tmp.columns = [\"diagnosis\", \"count\"]\n",
    "    tmp[\"split\"] = fname.replace(\".csv\", \"\")\n",
    "    all_stats.append(tmp)\n",
    "\n",
    "# –æ–±—ä–µ–¥–∏–Ω—è–µ–º\n",
    "df_stats = pd.concat(all_stats)\n",
    "\n",
    "# —Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞\n",
    "pivot = df_stats.pivot_table(\n",
    "    index=\"diagnosis\",\n",
    "    columns=\"split\",\n",
    "    values=\"count\",\n",
    "    fill_value=0,\n",
    "    aggfunc=\"sum\"\n",
    ")\n",
    "\n",
    "# int –≤–º–µ—Å—Ç–æ float\n",
    "pivot = pivot.astype(int)\n",
    "\n",
    "# –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É total (—Å—É–º–º–∞ –ø–æ diagnosis)\n",
    "pivot.loc[\"total\"] = pivot.sum()\n",
    "\n",
    "print(\"\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ diagnosis –ü–ê–†–ö–ò–ù–°–û–ù (—Å—á–∏—Ç–∞–µ–º –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º video_id):\")\n",
    "print(pivot.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2927a9d4-d147-4df8-8802-f7f33ae01b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ diagnosis DEPRESSION (—Å—á–∏—Ç–∞–µ–º –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º video_id):\n",
      "split      dev_labels_segments_min_filtered  test_labels_segments_min_filtered  train_labels_segments_min_filtered\n",
      "diagnosis                                                                                                         \n",
      "0                                        29                                 27                                 156\n",
      "1                                        27                                 28                                 135\n",
      "total                                    56                                 55                                 291\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\depression\")\n",
    "SETS = [\"dev_labels_segments_min_filtered.csv\", \"test_labels_segments_min_filtered.csv\", \"train_labels_segments_min_filtered.csv\"]\n",
    "\n",
    "all_stats = []\n",
    "\n",
    "\n",
    "for fname in SETS:\n",
    "    path = BASE / fname\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # —É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏ –ø–æ video_id (–µ—Å–ª–∏ –≤–¥—Ä—É–≥ –µ—Å—Ç—å)\n",
    "    df_unique = df.drop_duplicates(subset=[\"video_id\"])\n",
    "\n",
    "    counts = df_unique[\"diagnosis\"].value_counts().sort_index()\n",
    "    tmp = counts.reset_index()\n",
    "    tmp.columns = [\"diagnosis\", \"count\"]\n",
    "    tmp[\"split\"] = fname.replace(\".csv\", \"\")\n",
    "    all_stats.append(tmp)\n",
    "\n",
    "# –æ–±—ä–µ–¥–∏–Ω—è–µ–º\n",
    "df_stats = pd.concat(all_stats)\n",
    "\n",
    "# —Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞\n",
    "pivot = df_stats.pivot_table(\n",
    "    index=\"diagnosis\",\n",
    "    columns=\"split\",\n",
    "    values=\"count\",\n",
    "    fill_value=0,\n",
    "    aggfunc=\"sum\"\n",
    ")\n",
    "\n",
    "# int –≤–º–µ—Å—Ç–æ float\n",
    "pivot = pivot.astype(int)\n",
    "\n",
    "# –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É total (—Å—É–º–º–∞ –ø–æ diagnosis)\n",
    "pivot.loc[\"total\"] = pivot.sum()\n",
    "\n",
    "print(\"\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ diagnosis DEPRESSION (—Å—á–∏—Ç–∞–µ–º –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º video_id):\")\n",
    "print(pivot.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f2a8bf2-b70b-4b57-9bb0-545de0a31f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–°–≤–æ–¥–∫–∞ –ø–æ —á–∏—Å—Ç–∫–µ A –Ω–∞ –æ—Å–Ω–æ–≤–µ B:\n",
      "            metric  value\n",
      "   unique_ids_in_A     47\n",
      "   unique_ids_in_B     44\n",
      "ids_removed_from_A      3\n",
      "  rows_in_A_before    316\n",
      "   rows_in_A_after    312\n",
      "      rows_removed      4\n",
      "\n",
      "–ü–µ—Ä–≤—ã–µ 3 ID, –∫–æ—Ç–æ—Ä—ã—Ö –ù–ï–¢ –≤ B –∏ –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã –∏–∑ A:\n",
      "87mxEmx7zeA\n",
      "NUeEFVy2Ojw\n",
      "U74-VmwOeGI\n",
      "\n",
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: E:\\WSM\\parkinson\\dev_labels_segments_min_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\parkinson\")\n",
    "\n",
    "# üëâ –£–ö–ê–ñ–ò —Å–≤–æ–∏ —Ñ–∞–π–ª—ã\n",
    "FILE_A = BASE / \"dev_labels_segments_min.csv\"      # —Ñ–∞–π–ª —Å–æ —Å—Ç—Ä–æ–∫–∞–º–∏ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º (–º–Ω–æ–≥–æ —Å—Ç—Ä–æ–∫ –Ω–∞ 1 video_id)\n",
    "FILE_B = BASE / \"dev_w_fe_vid.csv\"            # —Ñ–∞–π–ª-—ç—Ç–∞–ª–æ–Ω —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ video_id\n",
    "\n",
    "SAVE = True  # True ‚Äî —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π A –≤ –Ω–æ–≤—ã–π CSV\n",
    "\n",
    "# 1) —á–∏—Ç–∞–µ–º –∏ –ø—Ä–∏–≤–æ–¥–∏–º video_id –∫ —Å—Ç—Ä–æ–∫–µ\n",
    "df_a = pd.read_csv(FILE_A)\n",
    "df_b = pd.read_csv(FILE_B)\n",
    "\n",
    "df_a[\"video_id\"] = df_a[\"video_id\"].astype(str)\n",
    "df_b[\"video_id\"] = df_b[\"video_id\"].astype(str)\n",
    "\n",
    "# 2) –º–Ω–æ–∂–µ—Å—Ç–≤–æ –≤–∞–ª–∏–¥–Ω—ã—Ö ID –∏–∑ —Ñ–∞–π–ª–∞ B (—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ)\n",
    "ids_b = set(df_b[\"video_id\"].unique())\n",
    "\n",
    "# 3) —á—Ç–æ –µ—Å—Ç—å –≤ A\n",
    "ids_a = set(df_a[\"video_id\"].unique())\n",
    "\n",
    "# 4) –∫–æ–≥–æ –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å –∏–∑ A (–≤ A –µ—Å—Ç—å, –≤ B –Ω–µ—Ç)\n",
    "ids_to_drop = sorted(ids_a - ids_b)\n",
    "\n",
    "# 5) —Ñ–∏–ª—å—Ç—Ä—É–µ–º A, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Ç–µ—Ö, –∫—Ç–æ –µ—Å—Ç—å –≤ B\n",
    "mask = df_a[\"video_id\"].isin(ids_b)\n",
    "df_a_filtered = df_a[mask].copy()\n",
    "\n",
    "# 6) –º–∏–Ω–∏-–æ—Ç—á—ë—Ç\n",
    "report = pd.DataFrame({\n",
    "    \"metric\": [\n",
    "        \"unique_ids_in_A\",\n",
    "        \"unique_ids_in_B\",\n",
    "        \"ids_removed_from_A\",\n",
    "        \"rows_in_A_before\",\n",
    "        \"rows_in_A_after\",\n",
    "        \"rows_removed\"\n",
    "    ],\n",
    "    \"value\": [\n",
    "        len(ids_a),\n",
    "        len(ids_b),\n",
    "        len(ids_to_drop),\n",
    "        len(df_a),\n",
    "        len(df_a_filtered),\n",
    "        len(df_a) - len(df_a_filtered)\n",
    "    ]\n",
    "})\n",
    "print(\"\\n–°–≤–æ–¥–∫–∞ –ø–æ —á–∏—Å—Ç–∫–µ A –Ω–∞ –æ—Å–Ω–æ–≤–µ B:\")\n",
    "print(report.to_string(index=False))\n",
    "\n",
    "# 7) –ø–æ–∫–∞–∂–µ–º –ø–µ—Ä–≤—ã–µ N —É–¥–∞–ª—è–µ–º—ã—Ö ID (—á—Ç–æ–±—ã –≥–ª–∞–∑–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å)\n",
    "N = 20\n",
    "if ids_to_drop:\n",
    "    print(f\"\\n–ü–µ—Ä–≤—ã–µ {min(N, len(ids_to_drop))} ID, –∫–æ—Ç–æ—Ä—ã—Ö –ù–ï–¢ –≤ B –∏ –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã –∏–∑ A:\")\n",
    "    print(pd.Series(ids_to_drop[:N]).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n–£–¥–∞–ª—è—Ç—å –ø–æ ID –Ω–µ—á–µ–≥–æ ‚Äî –≤—Å—ë –∏–∑ A –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ B. –ù–∞ —ç—Ç–æ—Ç —Ä–∞–∑ —Ç—ã —Å–ø—Ä–∞–≤–∏–ª—Å—è :)\")\n",
    "\n",
    "# 8) —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ –∂–µ–ª–∞–Ω–∏—é\n",
    "if SAVE:\n",
    "    out_path = FILE_A.with_name(FILE_A.stem + \"_filtered.csv\")\n",
    "    df_a_filtered.to_csv(out_path, index=False)\n",
    "    print(f\"\\n–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {out_path}\")\n",
    "else:\n",
    "    print(\"\\nSAVE=False ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—é. –í–æ–∑—å–º–∏ df_a_filtered –∏–∑ –ø–∞–º—è—Ç–∏, –µ—Å–ª–∏ –∑–∞–ø—É—Å–∫–∞–µ—à—å –≤ –Ω–æ—É—Ç–±—É–∫–µ.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4755dfa4-a9ea-46e3-9079-b8dfbff7a336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ video_id –≤ test_labels_segments_min_filtered.csv: 46\n",
      "–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ video_id –≤ test_w_fe_vid.csv: 46\n",
      "\n",
      "IDs –∏–∑ test_labels_segments_min_filtered.csv, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ test_w_fe_vid.csv (0):\n",
      "[]\n",
      "\n",
      "IDs –∏–∑ test_w_fe_vid.csv, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ test_labels_segments_min_filtered.csv (0):\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\parkinson\")\n",
    "\n",
    "# –∫–∞–∫–∏–µ –¥–≤–∞ —Ñ–∞–π–ª–∞ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º\n",
    "FILE_A = BASE / \"test_labels_segments_min_filtered.csv\"\n",
    "FILE_B = BASE / \"test_w_fe_vid.csv\"\n",
    "\n",
    "# —á–∏—Ç–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ video_id\n",
    "ids_a = set(pd.read_csv(FILE_A)[\"video_id\"].astype(str).unique())\n",
    "ids_b = set(pd.read_csv(FILE_B)[\"video_id\"].astype(str).unique())\n",
    "\n",
    "# —Ä–∞–∑–Ω–æ—Å—Ç–∏\n",
    "missing_in_b = sorted(ids_a - ids_b)\n",
    "missing_in_a = sorted(ids_b - ids_a)\n",
    "\n",
    "print(f\"\\n–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ video_id –≤ {FILE_A.name}: {len(ids_a)}\")\n",
    "print(f\"–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ video_id –≤ {FILE_B.name}: {len(ids_b)}\")\n",
    "\n",
    "print(f\"\\nIDs –∏–∑ {FILE_A.name}, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ {FILE_B.name} ({len(missing_in_b)}):\")\n",
    "print(missing_in_b[:20])  # –ø–µ—Ä–≤—ã–µ 20\n",
    "\n",
    "print(f\"\\nIDs –∏–∑ {FILE_B.name}, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ {FILE_A.name} ({len(missing_in_a)}):\")\n",
    "print(missing_in_a[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d04fd088-6109-4be9-afde-dd9060b630c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ diagnosis –ü–ê–†–ö–ò–ù–°–û–ù (–ø–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º video_id):\n",
      "split      dev_labels_segments_min_filtered  test_labels_segments_min_filtered  train_labels_segments_min_filtered\n",
      "diagnosis                                                                                                         \n",
      "0                                        22                                 25                                 132\n",
      "1                                        22                                 21                                 140\n",
      "total                                    44                                 46                                 272\n",
      "\n",
      "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ diagnosis –ü–ê–†–ö–ò–ù–°–û–ù (–ø–æ –≤—Å–µ–º —Å—Ç—Ä–æ–∫–∞–º / —Å–µ–≥–º–µ–Ω—Ç–∞–º):\n",
      "split      dev_labels_segments_min_filtered  test_labels_segments_min_filtered  train_labels_segments_min_filtered\n",
      "diagnosis                                                                                                         \n",
      "0                                       207                                404                                1678\n",
      "1                                       105                                133                                1058\n",
      "total                                   312                                537                                2736\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\parkinson\")\n",
    "SETS = [\n",
    "    \"dev_labels_segments_min_filtered.csv\",\n",
    "    \"test_labels_segments_min_filtered.csv\",\n",
    "    \"train_labels_segments_min_filtered.csv\"\n",
    "]\n",
    "\n",
    "# ===== –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º video_id =====\n",
    "all_stats_unique = []\n",
    "\n",
    "for fname in SETS:\n",
    "    path = BASE / fname\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ video_id\n",
    "    df_unique = df.drop_duplicates(subset=[\"video_id\"])\n",
    "\n",
    "    counts = df_unique[\"diagnosis\"].value_counts().sort_index()\n",
    "    tmp = counts.reset_index()\n",
    "    tmp.columns = [\"diagnosis\", \"count\"]\n",
    "    tmp[\"split\"] = fname.replace(\".csv\", \"\")\n",
    "    all_stats_unique.append(tmp)\n",
    "\n",
    "df_stats_unique = pd.concat(all_stats_unique)\n",
    "\n",
    "pivot_unique = df_stats_unique.pivot_table(\n",
    "    index=\"diagnosis\",\n",
    "    columns=\"split\",\n",
    "    values=\"count\",\n",
    "    fill_value=0,\n",
    "    aggfunc=\"sum\"\n",
    ").astype(int)\n",
    "\n",
    "pivot_unique.loc[\"total\"] = pivot_unique.sum()\n",
    "\n",
    "print(\"\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ diagnosis –ü–ê–†–ö–ò–ù–°–û–ù (–ø–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º video_id):\")\n",
    "print(pivot_unique.to_string())\n",
    "\n",
    "# ===== –ø–æ –≤—Å–µ–º —Å—Ç—Ä–æ–∫–∞–º (—Å–µ–≥–º–µ–Ω—Ç–∞–º) =====\n",
    "all_stats_all = []\n",
    "\n",
    "for fname in SETS:\n",
    "    path = BASE / fname\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    counts = df[\"diagnosis\"].value_counts().sort_index()\n",
    "    tmp = counts.reset_index()\n",
    "    tmp.columns = [\"diagnosis\", \"count\"]\n",
    "    tmp[\"split\"] = fname.replace(\".csv\", \"\")\n",
    "    all_stats_all.append(tmp)\n",
    "\n",
    "df_stats_all = pd.concat(all_stats_all)\n",
    "\n",
    "pivot_all = df_stats_all.pivot_table(\n",
    "    index=\"diagnosis\",\n",
    "    columns=\"split\",\n",
    "    values=\"count\",\n",
    "    fill_value=0,\n",
    "    aggfunc=\"sum\"\n",
    ").astype(int)\n",
    "\n",
    "pivot_all.loc[\"total\"] = pivot_all.sum()\n",
    "\n",
    "print(\"\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ diagnosis –ü–ê–†–ö–ò–ù–°–û–ù (–ø–æ –≤—Å–µ–º —Å—Ç—Ä–æ–∫–∞–º / —Å–µ–≥–º–µ–Ω—Ç–∞–º):\")\n",
    "print(pivot_all.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6fdd70fa-c488-46e5-bc8e-48c72cf039d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ diagnosis –î–ï–ü–†–ï–°–°–ò–Ø (–ø–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º video_id):\n",
      "split      dev_labels_segments_min_filtered  test_labels_segments_min_filtered  train_labels_segments_min_filtered\n",
      "diagnosis                                                                                                         \n",
      "0                                        29                                 27                                 156\n",
      "1                                        27                                 28                                 135\n",
      "total                                    56                                 55                                 291\n",
      "\n",
      "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ diagnosis –î–ï–ü–†–ï–°–°–ò–Ø (–ø–æ –≤—Å–µ–º —Å—Ç—Ä–æ–∫–∞–º / —Å–µ–≥–º–µ–Ω—Ç–∞–º):\n",
      "split      dev_labels_segments_min_filtered  test_labels_segments_min_filtered  train_labels_segments_min_filtered\n",
      "diagnosis                                                                                                         \n",
      "0                                       307                                492                                2284\n",
      "1                                       317                                335                                1431\n",
      "total                                   624                                827                                3715\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"E:\\WSM\\depression\")\n",
    "SETS = [\n",
    "    \"dev_labels_segments_min_filtered.csv\",\n",
    "    \"test_labels_segments_min_filtered.csv\",\n",
    "    \"train_labels_segments_min_filtered.csv\"\n",
    "]\n",
    "\n",
    "# ===== –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º video_id =====\n",
    "all_stats_unique = []\n",
    "\n",
    "for fname in SETS:\n",
    "    path = BASE / fname\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ video_id\n",
    "    df_unique = df.drop_duplicates(subset=[\"video_id\"])\n",
    "\n",
    "    counts = df_unique[\"diagnosis\"].value_counts().sort_index()\n",
    "    tmp = counts.reset_index()\n",
    "    tmp.columns = [\"diagnosis\", \"count\"]\n",
    "    tmp[\"split\"] = fname.replace(\".csv\", \"\")\n",
    "    all_stats_unique.append(tmp)\n",
    "\n",
    "df_stats_unique = pd.concat(all_stats_unique)\n",
    "\n",
    "pivot_unique = df_stats_unique.pivot_table(\n",
    "    index=\"diagnosis\",\n",
    "    columns=\"split\",\n",
    "    values=\"count\",\n",
    "    fill_value=0,\n",
    "    aggfunc=\"sum\"\n",
    ").astype(int)\n",
    "\n",
    "pivot_unique.loc[\"total\"] = pivot_unique.sum()\n",
    "\n",
    "print(\"\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ diagnosis –î–ï–ü–†–ï–°–°–ò–Ø (–ø–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º video_id):\")\n",
    "print(pivot_unique.to_string())\n",
    "\n",
    "# ===== –ø–æ –≤—Å–µ–º —Å—Ç—Ä–æ–∫–∞–º (—Å–µ–≥–º–µ–Ω—Ç–∞–º) =====\n",
    "all_stats_all = []\n",
    "\n",
    "for fname in SETS:\n",
    "    path = BASE / fname\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    counts = df[\"diagnosis\"].value_counts().sort_index()\n",
    "    tmp = counts.reset_index()\n",
    "    tmp.columns = [\"diagnosis\", \"count\"]\n",
    "    tmp[\"split\"] = fname.replace(\".csv\", \"\")\n",
    "    all_stats_all.append(tmp)\n",
    "\n",
    "df_stats_all = pd.concat(all_stats_all)\n",
    "\n",
    "pivot_all = df_stats_all.pivot_table(\n",
    "    index=\"diagnosis\",\n",
    "    columns=\"split\",\n",
    "    values=\"count\",\n",
    "    fill_value=0,\n",
    "    aggfunc=\"sum\"\n",
    ").astype(int)\n",
    "\n",
    "pivot_all.loc[\"total\"] = pivot_all.sum()\n",
    "\n",
    "print(\"\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ diagnosis –î–ï–ü–†–ï–°–°–ò–Ø (–ø–æ –≤—Å–µ–º —Å—Ç—Ä–æ–∫–∞–º / —Å–µ–≥–º–µ–Ω—Ç–∞–º):\")\n",
    "print(pivot_all.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3d1a58-8278-447d-a733-684103a6673e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
