{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ecc9573-a463-4f4e-adaa-e70217539867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорты — трогай один раз и не мучай\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad9b087b-9156-4dad-8991-ef67baf1f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PATH = Path(r\"C:\\Prgrm\\BDCC_2025\\results\\results_mamba_2025-09-04_12-22-32\\overrides.txt\")\n",
    "\n",
    "# читаем текст (на случай кривой кодировки попробуем cp1251)\n",
    "try:\n",
    "    text = LOG_PATH.read_text(encoding=\"utf-8\")\n",
    "except UnicodeDecodeError:\n",
    "    text = LOG_PATH.read_text(encoding=\"cp1251\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "590f3fd2-3fbf-4308-bd12-5b53222c4f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>out_features</th>\n",
       "      <th>mamba_d_state</th>\n",
       "      <th>mamba_ker_size</th>\n",
       "      <th>mamba_layers</th>\n",
       "      <th>UAR_WSM_TEST</th>\n",
       "      <th>MF1_WSM_TEST</th>\n",
       "      <th>RECALL_C0_CONTROL_WSM_TEST</th>\n",
       "      <th>RECALL_C1_DEPRESSION_WSM_TEST</th>\n",
       "      <th>RECALL_C2_PARKINSON_WSM_TEST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>189</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6889</td>\n",
       "      <td>0.5701</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.7444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>177</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6883</td>\n",
       "      <td>0.5948</td>\n",
       "      <td>0.5837</td>\n",
       "      <td>0.7821</td>\n",
       "      <td>0.6992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>156</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6834</td>\n",
       "      <td>0.5757</td>\n",
       "      <td>0.5212</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.6692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6804</td>\n",
       "      <td>0.5831</td>\n",
       "      <td>0.5469</td>\n",
       "      <td>0.8627</td>\n",
       "      <td>0.6316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6799</td>\n",
       "      <td>0.6396</td>\n",
       "      <td>0.6987</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.4812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6784</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.7388</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>0.6992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>173</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6762</td>\n",
       "      <td>0.5590</td>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.8687</td>\n",
       "      <td>0.6767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6719</td>\n",
       "      <td>0.6065</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.7940</td>\n",
       "      <td>0.5789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>138</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6699</td>\n",
       "      <td>0.5756</td>\n",
       "      <td>0.5056</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>0.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6693</td>\n",
       "      <td>0.5971</td>\n",
       "      <td>0.6038</td>\n",
       "      <td>0.8478</td>\n",
       "      <td>0.5564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     step  hidden_dim  out_features  mamba_d_state  mamba_ker_size  \\\n",
       "188   189         512           128              4               4   \n",
       "176   177         512           128              3               3   \n",
       "155   156         256           512              4               2   \n",
       "15     16         128           128              3               4   \n",
       "5       6         128           128              2               3   \n",
       "86     87         256           128              2               3   \n",
       "172   173         512           128              3               2   \n",
       "156   157         256           512              4               3   \n",
       "137   138         256           512              2               2   \n",
       "88     89         256           128              2               4   \n",
       "\n",
       "     mamba_layers  UAR_WSM_TEST  MF1_WSM_TEST  RECALL_C0_CONTROL_WSM_TEST  \\\n",
       "188             4        0.6889        0.5701                      0.5134   \n",
       "176             4        0.6883        0.5948                      0.5837   \n",
       "155             4        0.6834        0.5757                      0.5212   \n",
       "15              2        0.6804        0.5831                      0.5469   \n",
       "5               4        0.6799        0.6396                      0.6987   \n",
       "86              4        0.6784        0.6280                      0.7388   \n",
       "172             3        0.6762        0.5590                      0.4833   \n",
       "156             2        0.6719        0.6065                      0.6429   \n",
       "137             4        0.6699        0.5756                      0.5056   \n",
       "88              3        0.6693        0.5971                      0.6038   \n",
       "\n",
       "     RECALL_C1_DEPRESSION_WSM_TEST  RECALL_C2_PARKINSON_WSM_TEST  \n",
       "188                         0.8090                        0.7444  \n",
       "176                         0.7821                        0.6992  \n",
       "155                         0.8597                        0.6692  \n",
       "15                          0.8627                        0.6316  \n",
       "5                           0.8597                        0.4812  \n",
       "86                          0.5970                        0.6992  \n",
       "172                         0.8687                        0.6767  \n",
       "156                         0.7940                        0.5789  \n",
       "137                         0.9701                        0.5338  \n",
       "88                          0.8478                        0.5564  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====== НАСТРОЙКИ СМОТРИ ЗДЕСЬ ======\n",
    "METRIC = \"UAR_WSM\"   # например: \"UAR_WSM\", \"MF1_WSM\", \"RECALL_C2_PARKINSON_WSM\"\n",
    "SPLIT  = \"TEST\"      # \"DEV\" или \"TEST\"\n",
    "TOP    = 10          # сколько верхних строк показывать\n",
    "ASC    = False       # False = по убыванию (лучшие сверху)\n",
    "INCLUDE_BOTH = False # True — показывать и DEV, и TEST; False — только выбранный сплит\n",
    "\n",
    "# ====== ДАЛЬШЕ МОЖЕШЬ НЕ ТРОГАТЬ ======\n",
    "\n",
    "def normalize_box_text(raw: str) -> str:\n",
    "    \"\"\"Убираем псевдографику и боковые │, оставляем чистый текст.\"\"\"\n",
    "    lines = []\n",
    "    for line in raw.splitlines():\n",
    "        s = line.rstrip(\"\\n\")\n",
    "        # пропускаем рамочные строки\n",
    "        if s.strip().startswith((\"┌\",\"└\",\"┐\",\"┘\",\"─\",\"—\",\"━\")):\n",
    "            continue\n",
    "        ss = s.strip()\n",
    "        # срезаем крайние вертикальные\n",
    "        if ss.startswith(\"│\") and ss.endswith(\"│\") and len(ss) >= 2:\n",
    "            ss = ss[1:-1]\n",
    "        elif ss.startswith(\"│\"):\n",
    "            ss = ss[1:]\n",
    "        else:\n",
    "            ss = s\n",
    "            if ss.rstrip().endswith(\"│\"):\n",
    "                ss = ss.rstrip()[:-1]\n",
    "        lines.append(ss.strip())\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Блок шага: имена параметров слева от \"=\", значения в скобках, тело до следующего \"Шаг N\" или конца\n",
    "BLOCK_RE = re.compile(\n",
    "    r\"Шаг\\s+(?P<step>\\d+):\\s*(?P<hpnames>[^=]+?)=\\s*\\((?P<hpvals>[^)]*)\\)\\s*(?P<body>.*?)(?=\\n\\s*Шаг\\s+\\d+:|\\Z)\",\n",
    "    re.DOTALL | re.UNICODE\n",
    ")\n",
    "SECTION_RE = re.compile(r\"Результаты\\s*\\((DEV|TEST)\\)\\s*:\\s*\", re.IGNORECASE | re.UNICODE)\n",
    "METRIC_LINE_RE = re.compile(r\"^\\s*(?P<key>[A-Z0-9_]+)\\s*=\\s*(?P<val>\\d+(?:\\.\\d+)?)\\s*$\", re.UNICODE)\n",
    "\n",
    "def coerce_value(s: str):\n",
    "    s = s.strip()\n",
    "    if not s or s.lower() in {\"none\", \"null\", \"nan\"}:\n",
    "        return None\n",
    "    if re.fullmatch(r\"[+-]?\\d+\", s):\n",
    "        try: return int(s)\n",
    "        except: pass\n",
    "    if re.fullmatch(r\"[+-]?\\d*\\.\\d+\", s):\n",
    "        try: return float(s)\n",
    "        except: pass\n",
    "    return s  # на случай текстовых гиперпараметров\n",
    "\n",
    "def parse_hp_names(names_raw: str) -> List[str]:\n",
    "    # \"a + b + c\" → [\"a\",\"b\",\"c\"]\n",
    "    return [x.strip() for x in names_raw.split(\"+\") if x.strip()]\n",
    "\n",
    "def parse_hp_vals(vals_raw: str) -> List[Any]:\n",
    "    # \"1, 2, None\" → [1, 2, None]\n",
    "    return [coerce_value(x) for x in vals_raw.split(\",\")]\n",
    "\n",
    "def kv_from_names_vals(names: List[str], vals: List[Any]) -> Dict[str, Any]:\n",
    "    out, n = {}, min(len(names), len(vals))\n",
    "    for i in range(n): out[names[i]] = vals[i]\n",
    "    for j in range(n, len(names)): out[names[j]] = None\n",
    "    return out\n",
    "\n",
    "def parse_section_metrics(text_block: str) -> Dict[str, float]:\n",
    "    metrics = {}\n",
    "    for line in text_block.splitlines():\n",
    "        m = METRIC_LINE_RE.match(line.strip())\n",
    "        if m:\n",
    "            metrics[m.group(\"key\").strip()] = float(m.group(\"val\"))\n",
    "    return metrics\n",
    "\n",
    "def split_dev_test(body: str) -> Tuple[Dict[str, float], Dict[str, float]]:\n",
    "    parts = list(SECTION_RE.split(body))\n",
    "    dev, test = {}, {}\n",
    "    for i in range(1, len(parts), 2):\n",
    "        tag = parts[i].upper()\n",
    "        text_part = parts[i+1]\n",
    "        if tag == \"DEV\":\n",
    "            dev = parse_section_metrics(text_part)\n",
    "        elif tag == \"TEST\":\n",
    "            test = parse_section_metrics(text_part)\n",
    "    return dev, test\n",
    "\n",
    "def parse_blocks_dynamic(text_src: str) -> List[Dict[str, Any]]:\n",
    "    text_clean = normalize_box_text(text_src)\n",
    "    rows = []\n",
    "    for m in BLOCK_RE.finditer(text_clean):\n",
    "        step = int(m.group(\"step\"))\n",
    "        hp_map = kv_from_names_vals(parse_hp_names(m.group(\"hpnames\")),\n",
    "                                    parse_hp_vals(m.group(\"hpvals\")))\n",
    "        dev, test = split_dev_test(m.group(\"body\"))\n",
    "        row = {\"step\": step, **hp_map}\n",
    "        for k, v in dev.items():  row[f\"{k}_DEV\"]  = v\n",
    "        for k, v in test.items(): row[f\"{k}_TEST\"] = v\n",
    "        rows.append(row)\n",
    "    rows.sort(key=lambda r: r[\"step\"])\n",
    "    return rows\n",
    "\n",
    "def rows_to_dataframe_dynamic(rows: List[Dict[str, Any]]) -> pd.DataFrame:\n",
    "    return pd.DataFrame(rows) if rows else pd.DataFrame()\n",
    "\n",
    "def view_sorted_split(df: pd.DataFrame, metric: str, split: str,\n",
    "                      top: int = 10, ascending: bool = False,\n",
    "                      include_both: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Параметры (step + все НЕ *_DEV/*_TEST), затем сортируемая метрика,\n",
    "    затем остальные метрики только выбранного сплита (если include_both=False).\n",
    "    \"\"\"\n",
    "    split = split.upper()\n",
    "    sort_col = f\"{metric}_{split}\"\n",
    "\n",
    "    # meta = step + все НЕ метрики (то есть гиперпараметры)\n",
    "    meta_cols = [\"step\"] + [c for c in df.columns\n",
    "                            if not (c.endswith(\"_DEV\") or c.endswith(\"_TEST\")) and c != \"step\"]\n",
    "\n",
    "    # Какие метрики вообще оставляем\n",
    "    all_metric_cols = [c for c in df.columns if c.endswith(\"_DEV\") or c.endswith(\"_TEST\")]\n",
    "    if include_both:\n",
    "        keep_metric_cols = all_metric_cols[:]\n",
    "    else:\n",
    "        keep_metric_cols = [c for c in all_metric_cols if c.endswith(f\"_{split}\")]\n",
    "\n",
    "    if sort_col not in keep_metric_cols:\n",
    "        available = sorted(set(c.rsplit(\"_\", 1)[0] for c in keep_metric_cols))\n",
    "        raise ValueError(f\"Колонка {sort_col} не найдена в выбранном сплите {split}. \"\n",
    "                         f\"Доступные метрики: {available}\")\n",
    "\n",
    "    # Сорт-метрика впереди, остальное — после, по алфавиту\n",
    "    metric_cols_ordered = [sort_col] + [c for c in sorted(keep_metric_cols) if c != sort_col]\n",
    "    ordered_cols = meta_cols + metric_cols_ordered\n",
    "\n",
    "    out = df.loc[:, ordered_cols].sort_values(sort_col, ascending=ascending)\n",
    "    return out.head(top)\n",
    "\n",
    "# ==== Парсим и показываем ====\n",
    "_rows = parse_blocks_dynamic(text)\n",
    "df = rows_to_dataframe_dynamic(_rows)\n",
    "\n",
    "result_table = view_sorted_split(df, metric=METRIC, split=SPLIT,\n",
    "                                 top=TOP, ascending=ASC, include_both=INCLUDE_BOTH)\n",
    "result_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a12469a-3648-43f4-94c1-1de42d388e01",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Колонка UAR_WSM_TEST не найдена в выбранном сплите TEST. Доступные метрики: []",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 140\u001b[39m\n\u001b[32m    137\u001b[39m _rows = parse_blocks_dynamic(text)\n\u001b[32m    138\u001b[39m df = rows_to_dataframe_dynamic(_rows)\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m result_table = \u001b[43mview_sorted_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMETRIC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSPLIT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mtop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTOP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[43m=\u001b[49m\u001b[43mASC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_both\u001b[49m\u001b[43m=\u001b[49m\u001b[43mINCLUDE_BOTH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m result_table\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 126\u001b[39m, in \u001b[36mview_sorted_split\u001b[39m\u001b[34m(df, metric, split, top, ascending, include_both)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sort_col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m keep_metric_cols:\n\u001b[32m    125\u001b[39m     available = \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(c.rsplit(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m keep_metric_cols))\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mКолонка \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msort_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m не найдена в выбранном сплите \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    127\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mДоступные метрики: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavailable\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# Сорт-метрика впереди, остальное — после, по алфавиту\u001b[39;00m\n\u001b[32m    130\u001b[39m metric_cols_ordered = [sort_col] + [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(keep_metric_cols) \u001b[38;5;28;01mif\u001b[39;00m c != sort_col]\n",
      "\u001b[31mValueError\u001b[39m: Колонка UAR_WSM_TEST не найдена в выбранном сплите TEST. Доступные метрики: []"
     ]
    }
   ],
   "source": [
    "# ====== НАСТРОЙКИ СМОТРИ ЗДЕСЬ ======\n",
    "METRIC = \"UAR_WSM\"   # например: \"UAR_WSM\", \"MF1_WSM\", \"RECALL_C2_PARKINSON_WSM\"\n",
    "SPLIT  = \"TEST\"      # \"DEV\" или \"TEST\"\n",
    "TOP    = 10          # сколько верхних строк показывать\n",
    "ASC    = False       # False = по убыванию (лучшие сверху)\n",
    "INCLUDE_BOTH = False # True — показывать и DEV, и TEST; False — только выбранный сплит\n",
    "\n",
    "# ====== ДАЛЬШЕ МОЖЕШЬ НЕ ТРОГАТЬ ======\n",
    "\n",
    "def normalize_box_text(raw: str) -> str:\n",
    "    \"\"\"Убираем псевдографику и боковые │, оставляем чистый текст.\"\"\"\n",
    "    lines = []\n",
    "    for line in raw.splitlines():\n",
    "        s = line.rstrip(\"\\n\")\n",
    "        # пропускаем рамочные строки\n",
    "        if s.strip().startswith((\"┌\",\"└\",\"┐\",\"┘\",\"─\",\"—\",\"━\")):\n",
    "            continue\n",
    "        ss = s.strip()\n",
    "        # срезаем крайние вертикальные\n",
    "        if ss.startswith(\"│\") and ss.endswith(\"│\") and len(ss) >= 2:\n",
    "            ss = ss[1:-1]\n",
    "        elif ss.startswith(\"│\"):\n",
    "            ss = ss[1:]\n",
    "        else:\n",
    "            ss = s\n",
    "            if ss.rstrip().endswith(\"│\"):\n",
    "                ss = ss.rstrip()[:-1]\n",
    "        lines.append(ss.strip())\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Блок шага: имена параметров слева от \"=\", значения в скобках, тело до следующего \"Шаг N\" или конца\n",
    "BLOCK_RE = re.compile(\n",
    "    r\"Шаг\\s+(?P<step>\\d+):\\s*(?P<hpnames>[^=]+?)=\\s*\\((?P<hpvals>[^)]*)\\)\\s*(?P<body>.*?)(?=\\n\\s*Шаг\\s+\\d+:|\\Z)\",\n",
    "    re.DOTALL | re.UNICODE\n",
    ")\n",
    "SECTION_RE = re.compile(r\"Результаты\\s*\\((DEV|TEST)\\)\\s*:\\s*\", re.IGNORECASE | re.UNICODE)\n",
    "METRIC_LINE_RE = re.compile(r\"^\\s*(?P<key>[A-Z0-9_]+)\\s*=\\s*(?P<val>\\d+(?:\\.\\d+)?)\\s*$\", re.UNICODE)\n",
    "\n",
    "def coerce_value(s: str):\n",
    "    s = s.strip()\n",
    "    if not s or s.lower() in {\"none\", \"null\", \"nan\"}:\n",
    "        return None\n",
    "    if re.fullmatch(r\"[+-]?\\d+\", s):\n",
    "        try: return int(s)\n",
    "        except: pass\n",
    "    if re.fullmatch(r\"[+-]?\\d*\\.\\d+\", s):\n",
    "        try: return float(s)\n",
    "        except: pass\n",
    "    return s  # на случай текстовых гиперпараметров\n",
    "\n",
    "def parse_hp_names(names_raw: str) -> List[str]:\n",
    "    # \"a + b + c\" → [\"a\",\"b\",\"c\"]\n",
    "    return [x.strip() for x in names_raw.split(\"+\") if x.strip()]\n",
    "\n",
    "def parse_hp_vals(vals_raw: str) -> List[Any]:\n",
    "    # \"1, 2, None\" → [1, 2, None]\n",
    "    return [coerce_value(x) for x in vals_raw.split(\",\")]\n",
    "\n",
    "def kv_from_names_vals(names: List[str], vals: List[Any]) -> Dict[str, Any]:\n",
    "    out, n = {}, min(len(names), len(vals))\n",
    "    for i in range(n): out[names[i]] = vals[i]\n",
    "    for j in range(n, len(names)): out[names[j]] = None\n",
    "    return out\n",
    "\n",
    "def parse_section_metrics(text_block: str) -> Dict[str, float]:\n",
    "    metrics = {}\n",
    "    for line in text_block.splitlines():\n",
    "        m = METRIC_LINE_RE.match(line.strip())\n",
    "        if m:\n",
    "            metrics[m.group(\"key\").strip()] = float(m.group(\"val\"))\n",
    "    return metrics\n",
    "\n",
    "def split_dev_test(body: str) -> Tuple[Dict[str, float], Dict[str, float]]:\n",
    "    parts = list(SECTION_RE.split(body))\n",
    "    dev, test = {}, {}\n",
    "    for i in range(1, len(parts), 2):\n",
    "        tag = parts[i].upper()\n",
    "        text_part = parts[i+1]\n",
    "        if tag == \"DEV\":\n",
    "            dev = parse_section_metrics(text_part)\n",
    "        elif tag == \"TEST\":\n",
    "            test = parse_section_metrics(text_part)\n",
    "    return dev, test\n",
    "\n",
    "def parse_blocks_dynamic(text_src: str) -> List[Dict[str, Any]]:\n",
    "    text_clean = normalize_box_text(text_src)\n",
    "    rows = []\n",
    "    for m in BLOCK_RE.finditer(text_clean):\n",
    "        step = int(m.group(\"step\"))\n",
    "        hp_map = kv_from_names_vals(parse_hp_names(m.group(\"hpnames\")),\n",
    "                                    parse_hp_vals(m.group(\"hpvals\")))\n",
    "        dev, test = split_dev_test(m.group(\"body\"))\n",
    "        row = {\"step\": step, **hp_map}\n",
    "        for k, v in dev.items():  row[f\"{k}_DEV\"]  = v\n",
    "        for k, v in test.items(): row[f\"{k}_TEST\"] = v\n",
    "        rows.append(row)\n",
    "    rows.sort(key=lambda r: r[\"step\"])\n",
    "    return rows\n",
    "\n",
    "def rows_to_dataframe_dynamic(rows: List[Dict[str, Any]]) -> pd.DataFrame:\n",
    "    return pd.DataFrame(rows) if rows else pd.DataFrame()\n",
    "\n",
    "def view_sorted_split(df: pd.DataFrame, metric: str, split: str,\n",
    "                      top: int = 10, ascending: bool = False,\n",
    "                      include_both: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Параметры (step + все НЕ *_DEV/*_TEST), затем сортируемая метрика,\n",
    "    затем остальные метрики только выбранного сплита (если include_both=False).\n",
    "    \"\"\"\n",
    "    split = split.upper()\n",
    "    sort_col = f\"{metric}_{split}\"\n",
    "\n",
    "    # meta = step + все НЕ метрики (то есть гиперпараметры)\n",
    "    meta_cols = [\"step\"] + [c for c in df.columns\n",
    "                            if not (c.endswith(\"_DEV\") or c.endswith(\"_TEST\")) and c != \"step\"]\n",
    "\n",
    "    # Какие метрики вообще оставляем\n",
    "    all_metric_cols = [c for c in df.columns if c.endswith(\"_DEV\") or c.endswith(\"_TEST\")]\n",
    "    if include_both:\n",
    "        keep_metric_cols = all_metric_cols[:]\n",
    "    else:\n",
    "        keep_metric_cols = [c for c in all_metric_cols if c.endswith(f\"_{split}\")]\n",
    "\n",
    "    if sort_col not in keep_metric_cols:\n",
    "        available = sorted(set(c.rsplit(\"_\", 1)[0] for c in keep_metric_cols))\n",
    "        raise ValueError(f\"Колонка {sort_col} не найдена в выбранном сплите {split}. \"\n",
    "                         f\"Доступные метрики: {available}\")\n",
    "\n",
    "    # Сорт-метрика впереди, остальное — после, по алфавиту\n",
    "    metric_cols_ordered = [sort_col] + [c for c in sorted(keep_metric_cols) if c != sort_col]\n",
    "    ordered_cols = meta_cols + metric_cols_ordered\n",
    "\n",
    "    out = df.loc[:, ordered_cols].sort_values(sort_col, ascending=ascending)\n",
    "    return out.head(top)\n",
    "\n",
    "# ==== Парсим и показываем ====\n",
    "_rows = parse_blocks_dynamic(text)\n",
    "df = rows_to_dataframe_dynamic(_rows)\n",
    "\n",
    "result_table = view_sorted_split(df, metric=METRIC, split=SPLIT,\n",
    "                                 top=TOP, ascending=ASC, include_both=INCLUDE_BOTH)\n",
    "result_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16889e81-4872-4203-8d0d-5e0a1f13cf0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f1f774-ffb2-4890-b290-f6ae3a546814",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_transformer_2025-09-05_08-42-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9362c15e-6b34-43a1-b2f8-3bd9b8609e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
