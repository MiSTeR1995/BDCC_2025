# main.py
# coding: utf-8
import logging
import os
import shutil
import datetime
import toml

from tqdm import tqdm
from src.utils.config_loader import ConfigLoader
from src.utils.logger_setup import setup_logger
from src.utils.search_utils import greedy_search, exhaustive_search

from src.data_loading.dataset_builder import make_wsm_dataset_and_loader
from src.data_loading.pretrained_extractors import build_extractors_from_config

from transformers import CLIPProcessor, AutoImageProcessor

# Ğ•ÑĞ»Ğ¸ Ñƒ Ñ‚ĞµĞ±Ñ ĞµÑÑ‚ÑŒ Ñ‚Ñ€ĞµĞ½ĞµÑ€ â€” Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ğ¸Ğ¼. Ğ˜Ğ½Ğ°Ñ‡Ğµ Ğ¼Ğ¾Ğ¶ĞµÑˆÑŒ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ Ğ·Ğ°ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ¸Ñ‚ÑŒ.
from src.train import train


def _any_split_exists(cfg, split_name: str) -> bool:
    """
    ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ĞµÑÑ‚ÑŒ Ğ»Ğ¸ Ñ…Ğ¾Ñ‚ÑŒ Ğ¾Ğ´Ğ¸Ğ½ CSV Ğ´Ğ»Ñ Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ split ÑÑ€ĞµĞ´Ğ¸ ÑĞµĞºÑ†Ğ¸Ğ¹ datasets.wsm_*.
    """
    for ds_name, ds_cfg in getattr(cfg, "datasets", {}).items():
        if not ds_name.lower().startswith("wsm_"):
            continue
        csv_path = ds_cfg["csv_path"].format(base_dir=ds_cfg["base_dir"], split=split_name)
        if os.path.exists(csv_path):
            return True
    return False


def main():
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ Ğ¸ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    base_config = ConfigLoader("config.toml")

    model_name = base_config.model_name.replace("/", "_").replace(" ", "_").lower()
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    results_dir = f"results/results_{model_name}_{timestamp}"
    os.makedirs(results_dir, exist_ok=True)

    base_config.checkpoint_dir = os.path.join(results_dir, "checkpoints")
    os.makedirs(base_config.checkpoint_dir, exist_ok=True)

    epochlog_dir = os.path.join(results_dir, "metrics_by_epoch")
    os.makedirs(epochlog_dir, exist_ok=True)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    log_file = os.path.join(results_dir, "session_log.txt")
    setup_logger(logging.INFO, log_file=log_file)
    base_config.show_config()

    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ¼ ĞºĞ¾Ğ¿Ğ¸Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ° Ğ¸ Ğ¼ĞµÑÑ‚Ğ¾ Ğ´Ğ»Ñ Ğ¾Ğ²ĞµÑ€Ñ€Ğ°Ğ¹Ğ´Ğ¾Ğ² Ğ¿Ğ¾Ğ¸ÑĞºĞ°
    shutil.copy("config.toml", os.path.join(results_dir, "config_copy.toml"))
    overrides_file = os.path.join(results_dir, "overrides.txt")
    csv_prefix = os.path.join(epochlog_dir, "metrics_epochlog")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. Ğ­ĞºÑÑ‚Ñ€Ğ°ĞºÑ‚Ğ¾Ñ€Ñ‹/Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ñ‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logging.info("ğŸ”§ Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞºÑÑ‚Ñ€Ğ°ĞºÑ‚Ğ¾Ñ€Ğ¾Ğ² Ğ¿Ğ¾ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ñƒ (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ BODY)...")

    # Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ•: Ğ½Ğ°Ñˆ build_extractors_from_config Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ ĞºĞ»ÑÑ‡ 'body'
    modality_extractors = build_extractors_from_config(base_config)

    # Processor Ğ¿Ğ¾Ğ´ Ğ²Ğ¸Ğ´ĞµĞ¾: AutoImageProcessor Ğ´Ğ»Ñ ViT, CLIPProcessor Ğ´Ğ»Ñ CLIP
    if getattr(base_config, "video_extractor", "").lower() == "off":
        raise ValueError("video_extractor='off' Ğ½Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ°Ğ½ â€” Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ processor Ğ´Ğ»Ñ 'body'.")

    model_name = base_config.video_extractor
    try:
        if "vit" in model_name.lower():
            body_processor = AutoImageProcessor.from_pretrained(model_name)
        else:
            body_processor = CLIPProcessor.from_pretrained(model_name)
    except Exception as e:
        raise RuntimeError(
            f"ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ image processor Ğ¸Ğ· '{model_name}'. "
            f"ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ config.video_extractor. ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}"
        )

    modality_processors = {"body": body_processor}

    # ĞŸĞ¾Ğ»Ğ¾Ğ¶Ğ¸Ğ¼ Ğ² ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ±Ğ¸Ğ»Ğ´ĞµÑ€ Ğ¼Ğ¾Ğ³ Ğ¸Ñ… Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ
    base_config.modality_extractors = modality_extractors
    base_config.modality_processors = modality_processors

    enabled = ", ".join(sorted(modality_extractors.keys())) or "â€”"
    logging.info(f"âœ… ĞĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸: {enabled}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. Ğ”Ğ°Ñ‚Ğ°Ğ»Ğ¾Ğ°Ğ´ĞµÑ€Ñ‹ (WSM) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ğ¼ dev/val: ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ñ…Ğ¾Ñ‚ÑŒ Ğ¾Ğ´Ğ¸Ğ½ dev-CSV â€” Ğ±ĞµÑ€Ñ‘Ğ¼ 'dev', Ğ¸Ğ½Ğ°Ñ‡Ğµ 'val'
    dev_split = "dev" if _any_split_exists(base_config, "dev") else "val"

    logging.info("ğŸ“¦ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ WSM (train/dev/test)...")
    _, train_loader = make_wsm_dataset_and_loader(base_config, "train")
    _, dev_loader   = make_wsm_dataset_and_loader(base_config, dev_split)

    # test: ĞµÑĞ»Ğ¸ Ğ½ĞµÑ‚ Ñ‚ĞµÑÑ‚Ğ° â€” Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ dev
    if _any_split_exists(base_config, "test"):
        _, test_loader = make_wsm_dataset_and_loader(base_config, "test")
    else:
        test_loader = dev_loader

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. Ğ ĞµĞ¶Ğ¸Ğ¼ prepare_only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if base_config.prepare_only:
        logging.info("== Ğ ĞµĞ¶Ğ¸Ğ¼ prepare_only: Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ ĞºÑÑˆĞ°, Ğ±ĞµĞ· Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ==")
        return

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. ĞŸĞ¾Ğ¸ÑĞº/Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    search_type = base_config.search_type

    dev_loaders  = {"wsm": dev_loader}
    test_loaders = {"wsm": test_loader}

    if search_type == "greedy":
        search_config = toml.load("search_params.toml")
        param_grid     = dict(search_config.get("grid", {}))
        default_values = dict(search_config.get("defaults", {}))

        greedy_search(
            base_config    = base_config,
            train_loader   = train_loader,
            dev_loader     = dev_loaders,
            test_loader    = test_loaders,
            train_fn       = train,
            overrides_file = overrides_file,
            param_grid     = param_grid,
            default_values = default_values,
        )

    elif search_type == "exhaustive":
        search_config = toml.load("search_params.toml")
        param_grid     = dict(search_config.get("grid", {}))

        exhaustive_search(
            base_config    = base_config,
            train_loader   = train_loader,
            dev_loader     = dev_loaders,
            test_loader    = test_loaders,
            train_fn       = train,
            overrides_file = overrides_file,
            param_grid     = param_grid,
        )

    elif search_type == "none":
        logging.info("== ĞĞ´Ğ¸Ğ½Ğ¾Ñ‡Ğ½Ğ°Ñ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° (Ğ±ĞµĞ· Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²) ==")
        train(
            cfg         = base_config,
            mm_loader   = train_loader,   # ĞµĞ´Ğ¸Ğ½Ñ‹Ğ¹ Ğ»Ğ¾Ğ°Ğ´ĞµÑ€ WSM
            dev_loaders = dev_loaders,
            test_loaders= test_loaders,
        )

    else:
        raise ValueError(
            f"â›”ï¸ ĞĞµĞ²ĞµÑ€Ğ½Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ search_type: '{base_config.search_type}'. "
            f"Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ 'greedy', 'exhaustive' Ğ¸Ğ»Ğ¸ 'none'."
        )


if __name__ == "__main__":
    main()
